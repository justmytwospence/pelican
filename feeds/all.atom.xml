<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>justmytwospence</title><link href="http://justmytwospence.github.com/pelican/" rel="alternate"></link><link href="http://justmytwospence.github.com/pelican/feeds/all.atom.xml" rel="self"></link><id>http://justmytwospence.github.com/pelican/</id><updated>2014-03-22T18:38:32+01:00</updated><entry><title>Stratified sampling in R</title><link href="http://justmytwospence.github.com/pelican/stratified-sampling-in-r.html" rel="alternate"></link><updated>2014-03-22T18:38:32+01:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2014-03-22:stratified-sampling-in-r.html</id><summary type="html">&lt;p&gt;I was surprised to find that R doesn’t have a base function for stratified random sampling. There’s not even a well known package I could find that does this in a straight forward way. So heres my&amp;nbsp;own.&lt;/p&gt;
&lt;p&gt;It is essentially a wrapper for a ddply call that samples each subset and then combines them. If the size argument is less than 1, it will be interpreted as the percentage of each stratification subset that should be sampled. If the size argument is greater than 1, it will be interpreted as the number of observations to sample from each stratification&amp;nbsp;subset. &lt;/p&gt;
&lt;p&gt;Note that in the first case, a different number of observations will be taken from each subset depending on their total number of observations. In the second case however, an equal number of observations will be sampled from each subset, regardless of their total number of&amp;nbsp;observations.&lt;/p&gt;
&lt;p&gt;The .by argument is formulated the same way it is for any other ddply&amp;nbsp;call.&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;script src="https://gist.github.com/justmytwospence/7937389.js"&gt;&lt;/script&gt;</summary></entry><entry><title>What's a Mooc?</title><link href="http://justmytwospence.github.com/pelican/whats-a-mooc.html" rel="alternate"></link><updated>2014-03-14T14:13:00+01:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2014-03-14:whats-a-mooc.html</id><summary type="html">&lt;p&gt;Turns out that Robert de Niro and friends are facing a problem very  similar to the one facing Coursera and&amp;nbsp;friends&amp;#8230;&lt;/p&gt;
&lt;div class="youtube" align="center"&gt;&lt;iframe width="420" height="315" src="https://www.youtube.com/embed/8vw8t4O9JQM" frameborder="0"&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;p&gt;From the 1973 movie &lt;a class="reference external" href="http://www.imdb.com/title/tt0070379/?ref_=fn_al_tt_1"&gt;Mean Streets&lt;/a&gt;. Apparently Scorsese predicted the education revolution wayy ahead of his time and had a pretty good grasp on the biggest challenges that MOOCs would need to&amp;nbsp;overcome.&lt;/p&gt;
</summary><category term="Coursera"></category><category term="education"></category><category term="MOOC"></category></entry><entry><title>writeLaTeX</title><link href="http://justmytwospence.github.com/pelican/writelatex.html" rel="alternate"></link><updated>2014-01-25T18:42:00+01:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2014-01-25:writelatex.html</id><summary type="html">&lt;p&gt;If you use \(\LaTeX\) and haven&amp;#8217;t yet heard of
\(write\LaTeX\), do yourself a favor and check it out. On one level
its a really great version of Google Docs for documents that are
properly typeset, which is incredibly useful because a huge swathe of
the documents created with \(\LaTeX\) are inherently collaborative in
nature. Its other fantastic feature is that your \(\LaTeX\) markup is
automatically rendered in real-time (or close to it, at least, there&amp;#8217;s a
few seconds of lag depending on the length of the document). This made
writing my first \(\LaTeX\) intensive document a great experience,
because I could experiment liberally with equations and figure
placement. There&amp;#8217;s literally zero barrier to entry because its
completely web based; you don&amp;#8217;t need to install a thing and templates
are available to get you jump-started. Right now other engines like
XeLaTeX aren&amp;#8217;t supported, but I believe they are in the&amp;nbsp;works.&lt;/p&gt;
&lt;p&gt;So every excuse you ever had to not learn \(\LaTeX\) has been
obliterated. Give [\(write\LaTeX\)][] a try, or be passive aggressive
and send it to that collaborator that always sends you everything in a
poorly formatted Word document. I myself will be experimenting with
using \(\LaTeX\) to take math-heavy notes in real-time, which sounds
crazy but the live rendering makes the attempt&amp;nbsp;feasible.&lt;/p&gt;</summary><category term="latex"></category><category term="tex"></category><category term="typesetting"></category><category term="writelatex"></category></entry><entry><title>Titanic: Getting Started With R</title><link href="http://justmytwospence.github.com/pelican/titanic-getting-started-with-r.html" rel="alternate"></link><updated>2014-01-11T22:05:00+01:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2014-01-11:titanic-getting-started-with-r.html</id><summary type="html">&lt;p&gt;My friend and classmate &lt;a href="http://trevorstephens.com"&gt;Trevor Stephens&lt;/a&gt; has created some &lt;a href="http://trevorstephens.com/post/72916401642/titanic-getting-started-with-r"&gt;pretty stellar R tutorials&lt;/a&gt; that will take you to about halfway up the leaderboard of Kaggle&amp;#8217;s &lt;a href="http://www.kaggle.com/c/titanic-gettingStarted"&gt;Titanic: Machine Learning from Disaster&lt;/a&gt; competition. While the competition has a &lt;a href="http://www.kaggle.com/c/titanic-gettingStarted/details/getting-started-with-python"&gt;Python tutorial&lt;/a&gt; and even a beginner&amp;#8217;s &lt;a href="http://www.kaggle.com/c/titanic-gettingStarted/details/getting-started-with-excel"&gt;Excel tutorial&lt;/a&gt;, any R equivalent had been suspiciously lacking. This is the competition that served as our first foray into machine learning, so kudos to Trevor for giving back to the&amp;nbsp;community!&lt;/p&gt;</summary><category term="kaggle"></category><category term="machine learning"></category><category term="R"></category></entry><entry><title>Live mapping</title><link href="http://justmytwospence.github.com/pelican/live-mapping.html" rel="alternate"></link><updated>2014-01-08T08:50:00+01:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2014-01-08:live-mapping.html</id><summary type="html">&lt;p&gt;I&amp;#8217;ve been wanting to do some more mapping stuff since my first encounter with Leaflet a month or two ago while I was working on a project for &lt;a href="http://auto-grid.com"&gt;AutoGrid&lt;/a&gt;. I had my eye on CartoDB&amp;#8217;s time series library, &lt;a href="https://github.com/cartodb/torque"&gt;Torque&lt;/a&gt;, because I had really wanted to do some time-series visualization, but time constraints and privacy issues with uploading data to CartoDB&amp;#8217;s servers prevented me from really exploring. Since I had a few days of free time over winter break, I played around with it a bit and came up with this: &lt;a href="http://www.spencerboucher.com/map"&gt;spencerboucher.com/map&lt;/a&gt;. How&amp;#8217;d I do it?
&lt;br/&gt;
First I needed some geographic data, so I turned to a source of data I&amp;#8217;ve been collected for almost a year - my own location. &lt;a href="http://openpaths.cc"&gt;OpenPaths&lt;/a&gt; is a mobile app that records your location at regular time intervals. I opted for every 30 minutes at first, then upped it to every 15 minutes when I discovered that the effect on battery life wasn&amp;#8217;t nearly as bad as I expected it to be. OpenPaths is a project of &lt;a href="http://nytlabs.com/"&gt;the R&amp;amp;D department at The New York Times&lt;/a&gt; and they &lt;a href="https://openpaths.cc/FAQ"&gt;claim&lt;/a&gt; that you are the only one with access to the collected data. Interestingly, you can grant various &lt;a href="https://openpaths.cc/projects"&gt;research programs&lt;/a&gt; access to your data at your own discretion. Your data is conveniently downloadable as a csv, json, or kml file, so I easily pulled my dataset of \~3,000 time points since December 2012. Unfortunately, I made the switch from iPhone to Android around April (well, that part is fortunate), and forgot to re-download the app, so I only really have data from the around the first three months and last two months of 2013.
&lt;br/&gt;
Turns out, making impressive maps with CartoDB is almost embarrassingly easy. Their &lt;span class="caps"&gt;GUI&lt;/span&gt; is pretty intuitive and running queries on their postgreSQL database is simple. Even time series stuff built on the Torque backend is really just point and click. I decided that the best way to visualize this data was with an aggregated hexbin heatmap of all my past locations, overlaid with a point-by-point replay with a time-slider. From there, it was just a one-line &lt;span class="caps"&gt;API&lt;/span&gt; call to host the map on my website (line 30 highlighted below), which is significantly easier than the legwork that went into crafting a Leaflet map&amp;nbsp;&amp;#8220;manually.&amp;#8221;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nt"&gt;&amp;lt;html&amp;gt;&lt;/span&gt;

&lt;span class="nt"&gt;&amp;lt;head&amp;gt;&lt;/span&gt;

  &lt;span class="nt"&gt;&amp;lt;meta&lt;/span&gt; &lt;span class="na"&gt;name=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;viewport&amp;quot;&lt;/span&gt; &lt;span class="na"&gt;content=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;initial-scale=1.0, user-scalable=no&amp;quot;&lt;/span&gt; &lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;

  &lt;span class="nt"&gt;&amp;lt;title&amp;gt;&lt;/span&gt;Location | Spencer&lt;span class="nt"&gt;&amp;lt;/title&amp;gt;&lt;/span&gt;

  &lt;span class="nt"&gt;&amp;lt;link&lt;/span&gt; &lt;span class="na"&gt;rel=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;shortcut icon&amp;quot;&lt;/span&gt; &lt;span class="na"&gt;href=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;http://spencerboucher.com/map/favicon.png&amp;quot;&lt;/span&gt; &lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;link&lt;/span&gt; &lt;span class="na"&gt;rel=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;stylesheet&amp;quot;&lt;/span&gt; &lt;span class="na"&gt;href=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;http://libs.cartocdn.com/cartodb.js/v3/themes/css/cartodb.css&amp;quot;&lt;/span&gt; &lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
  &lt;span class="c"&gt;&amp;lt;!--[if lte IE 8]&amp;gt;&lt;/span&gt;
&lt;span class="c"&gt;    &amp;lt;link rel=&amp;quot;stylesheet&amp;quot; href=&amp;quot;http://libs.cartocdn.com/cartodb.js/v3/themes/css/cartodb.ie.css&amp;quot; /&amp;gt;&lt;/span&gt;
&lt;span class="c"&gt;  &amp;lt;![endif]--&amp;gt;&lt;/span&gt;

  &lt;span class="nt"&gt;&amp;lt;style &lt;/span&gt;&lt;span class="na"&gt;type=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;text/css&amp;quot;&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
      &lt;span class="nt"&gt;html&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;body&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nf"&gt;#map&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
          &lt;span class="k"&gt;margin&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
          &lt;span class="k"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
          &lt;span class="k"&gt;width&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="m"&gt;100&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
          &lt;span class="k"&gt;height&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="m"&gt;100&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
          &lt;span class="k"&gt;background&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;black&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
      &lt;span class="nf"&gt;#cartodb-gmaps-attribution&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="k"&gt;visibility&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="k"&gt;hidden&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;/style&amp;gt;&lt;/span&gt;

  &lt;span class="nt"&gt;&amp;lt;script &lt;/span&gt;&lt;span class="na"&gt;src=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;http://maps.google.com/maps/api/js?v=3.2&amp;amp;sensor=false&amp;quot;&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&amp;lt;/script&amp;gt;&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;script &lt;/span&gt;&lt;span class="na"&gt;src=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;http://libs.cartocdn.com/cartodb.js/v3/cartodb.js&amp;quot;&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&amp;lt;/script&amp;gt;&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;script&amp;gt;&lt;/span&gt;
    &lt;span class="kd"&gt;function&lt;/span&gt; &lt;span class="nx"&gt;init&lt;/span&gt;&lt;span class="p"&gt;(){&lt;/span&gt;
      &lt;span class="nx"&gt;cartodb&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;createVis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;map&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;http://justmytwospence.cartodb.com/api/v2/viz/e8fd87d0-78b3-11e3-a9e9-e7941b6e2df0/viz.json&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;/script&amp;gt;&lt;/span&gt;

&lt;span class="nt"&gt;&amp;lt;/head&amp;gt;&lt;/span&gt;

&lt;span class="nt"&gt;&amp;lt;body&lt;/span&gt; &lt;span class="na"&gt;onload=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;init()&amp;quot;&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;div&lt;/span&gt; &lt;span class="na"&gt;id=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;map&amp;#39;&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&amp;lt;/div&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;/body&amp;gt;&lt;/span&gt;

&lt;span class="nt"&gt;&amp;lt;/html&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This is pretty awesome, but in light of how easy it all was, I was almost disappointed. Can we take it one step further? Let&amp;#8217;s put on our &lt;a href="http://quantifiedself.com/about/"&gt;Quantified Self&lt;/a&gt; hats and set about to make this map &lt;em&gt;live&lt;/em&gt;. There&amp;#8217;s three components to making this happen, so we&amp;#8217;ll step through them one at a time. First we need to access the most recent data from OpenPaths (there&amp;#8217;s an &lt;span class="caps"&gt;API&lt;/span&gt; for that!), and then we need to insert that data into CartoDB&amp;#8217;s database (guess what, there&amp;#8217;s an &lt;span class="caps"&gt;API&lt;/span&gt; for that too). Last but not least, we need to schedule that data transplant to occur on a regular basis. The Unix utility &lt;code&gt;cron&lt;/code&gt; is the canonical tool for this type of thing, so this seemed like a good time to learn how to use it.
&lt;/br&gt;
Python has a reputation for being a great &amp;#8220;glue&amp;#8221; language, so that&amp;#8217;s what we&amp;#8217;ll use to build this script.
&lt;br/&gt;
Programmatically accessing your data from OpenPaths is super simple. This piece of our script is pulled more or less verbatim from &lt;a href="https://openpaths.cc/api"&gt;the OpenPaths &lt;span class="caps"&gt;API&lt;/span&gt; documentation&lt;/a&gt;. Line 21 (highlighted below) is key - this is where we specify which data you want to pull for injection into the CartoDB database. Here we will grab the last 24 hours of data (\~96 readings, if you&amp;#8217;re collecting every 15 minutes like me), getting the results in a nice  &lt;span class="caps"&gt;JSON&lt;/span&gt;-formatted variable named &lt;code&gt;data&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;oauth2&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nn"&gt;time&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nn"&gt;urllib&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nn"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nn"&gt;json&lt;/span&gt;

&lt;span class="n"&gt;ACCESS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;redacted&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;SECRET&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;redacted&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;URL&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;https://openpaths.cc/api/1&amp;#39;&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;build_auth_header&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;method&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;params&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="s"&gt;&amp;#39;oauth_version&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;1.0&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s"&gt;&amp;#39;oauth_nonce&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;oauth2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;generate_nonce&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
        &lt;span class="s"&gt;&amp;#39;oauth_timestamp&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()),&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="n"&gt;consumer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;oauth2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Consumer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ACCESS&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;secret&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;SECRET&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;oauth_consumer_key&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;consumer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt; 
    &lt;span class="n"&gt;request&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;oauth2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Request&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;method&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;method&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;parameters&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;signature_method&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;oauth2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SignatureMethod_HMAC_SHA1&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sign_request&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;signature_method&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;consumer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_header&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;now&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;params&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;start_time&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;now&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;24&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="mi"&gt;60&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="mi"&gt;60&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;end_time&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;now&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="c"&gt;# get the last 24 hours&lt;/span&gt;
&lt;span class="n"&gt;query&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt;?&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;URL&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;urllib&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;urlencode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="c"&gt;#print(query)&lt;/span&gt;
&lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;request&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Request&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;query&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;headers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;build_auth_header&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;URL&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;GET&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;connection&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;urlopen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loads&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;connection&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;readlines&lt;/span&gt;&lt;span class="p"&gt;()))&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dumps&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;indent&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="n"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;HTTPError&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now we need to get our new &lt;code&gt;data&lt;/code&gt; variable into CartoDB&amp;#8217;s postgreSQL server. &lt;a href="http://developers.cartodb.com/documentation/sql-api.html"&gt;CartoDB&amp;#8217;s &lt;span class="caps"&gt;SQL&lt;/span&gt; &lt;span class="caps"&gt;API&lt;/span&gt; documentation&lt;/a&gt; makes this possible, and there&amp;#8217;s even a &lt;a href="https://github.com/vizzuality/cartodb-python"&gt;python module&lt;/a&gt; that wraps OAuth2 to simplify things. Although its still in the early stages of development, this module works fine for our current purposes; all we have to do is send it a string that holds the &lt;span class="caps"&gt;SQL&lt;/span&gt; query we want to run. So now we&amp;#8217;ll just write a for-loop that successively builds an &lt;code&gt;INSERT&lt;/code&gt; query for each element in &lt;code&gt;data&lt;/code&gt; (lines 18-20 highlighted&amp;nbsp;below).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;cartodb&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;CartoDBException&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;CartoDBAPIKey&lt;/span&gt;

&lt;span class="n"&gt;user&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="s"&gt;&amp;#39;spencer.g.boucher@gmail.com&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;password&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="s"&gt;&amp;#39;redacted&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;cartodb_domain&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;justmytwospence&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;API_KEY&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;redacted&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;cl&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;CartoDBAPIKey&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;API_KEY&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cartodb_domain&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;reading&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;alt&lt;/span&gt;     &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;reading&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;alt&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;device&lt;/span&gt;  &lt;span class="o"&gt;=&lt;/span&gt;     &lt;span class="n"&gt;reading&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;device&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;lat&lt;/span&gt;     &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;reading&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;lat&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;lon&lt;/span&gt;     &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;reading&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;lon&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;os&lt;/span&gt;      &lt;span class="o"&gt;=&lt;/span&gt;     &lt;span class="n"&gt;reading&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;os&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;t&lt;/span&gt;       &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;reading&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;t&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;version&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;     &lt;span class="n"&gt;reading&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;version&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;query_string&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;INSERT INTO openpaths_justmytwospence (alt, date, device, lat,  lon, os, version, the_geom) &amp;quot;&lt;/span&gt;
                       &lt;span class="s"&gt;&amp;quot;VALUES ({0}, abstime({1}), &amp;#39;{2}&amp;#39;, {3}, {4}, &amp;#39;{5}&amp;#39;, &amp;#39;{6}&amp;#39;, ST_ SetSRID(ST_Point({4}, {3}), 4326))&amp;quot;&lt;/span&gt;  
                      &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;alt&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;device&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lat&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lon&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;version&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;cl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sql&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;query_string&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="n"&gt;CartoDBException&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;some error ocurred&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;A few&amp;nbsp;notes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It would certainly be faster to insert all of the new data into the
    database using a single &lt;code&gt;INSERT&lt;/code&gt; statement, but that would require
    some more tedious text parsing and execution speed isn&amp;#8217;t
    particularly important to us. As it stands, it takes about six
    seconds to post a day&amp;#8217;s worth of&amp;nbsp;data.&lt;/li&gt;
&lt;li&gt;One posgreSQL &amp;#8220;gotcha&amp;#8221; had me hung up for quite some time: single
    quotes parse fine but double quotes do&amp;nbsp;not.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ST_SetSRID&lt;/code&gt; is a &lt;a href="http://postgis.org/docs/ST_SetSRID.html"&gt;PostGIS command&lt;/a&gt; that converts a lon/lat pair
    (in that order - another &amp;#8220;gotcha&amp;#8221;) to the necessary geometry&amp;nbsp;object.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Last but not least, we need this script to run automatically. Because we&amp;#8217;ve written the script to transplant 24 hours of data, we&amp;#8217;ll need to run it once a day in order to capture all of the data that&amp;#8217;s being generated. I tried to set up my web host, &lt;a href="https://laughingsquid.us/"&gt;LaughingSquid&lt;/a&gt;, to do this, but unfortunately they don&amp;#8217;t grant shell access so we can&amp;#8217;t install all those fancy python modules that we&amp;#8217;ve already used. Its totally possible to rewrite the script to use only modules from the &lt;a href="http://docs.python.org/2/library/"&gt;Python Standard Library&lt;/a&gt;, but this would turn a simple task into a tedious one. Manually implementing OAuth in particular would be a total pain in the rear, and classes are just about to resume after all, so a different solution is in order. Let&amp;#8217;s spin up a &lt;a href="http://aws.amazon.com/"&gt;&amp;#8220;micro&amp;#8221; &lt;span class="caps"&gt;EC2&lt;/span&gt; instance&lt;/a&gt; instead. This gives us free reign to install whatever we need for the low low cost of ¢.02 per hour. This does start to add up, but our Master&amp;#8217;s program gives us some pretty substantial Amazon Web Services credit that goes mostly unused, so we aren&amp;#8217;t too upset :). &lt;span class="caps"&gt;UPDATE&lt;/span&gt;: A new post provides details about how to schedule Amazon &lt;span class="caps"&gt;EC2&lt;/span&gt; instances - &lt;a href="http://www.spencerboucher.com/ec2-apis/"&gt;http://www.spencerboucher.com/ec2-apis/&lt;/a&gt;.
&lt;br/&gt;
After &lt;code&gt;pip install&lt;/code&gt;ing everything we need and &lt;code&gt;scp&lt;/code&gt;ing our python script (let&amp;#8217;s call it update.py) into the home directory of our remote server, all we need to do is set up a crontab with the &lt;code&gt;crontab -e&lt;/code&gt; command and add the following&amp;nbsp;line:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;@daily /usr/bin/python ~/update.py
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;@daily&lt;/code&gt; is actually a shortcut for &lt;code&gt;* * * * *&lt;/code&gt;, where each asterix is a
placeholder for the (respectively) minute, hour, day of month, month,
and day of week that the script should executed. This shortcut defaults
to midnight every day, which is really as good as anything for our
purposes.
&lt;br/&gt;
Voilà! Now we can step back and relax, knowing that we don&amp;#8217;t have to do a single thing and our map will continue to show the most up-to-date data available.
&lt;br/&gt;
A few final notes: 
-   We might reasonably want to lag our script by a week or so, for security/privacy reasons.
-   As far as I can tell, the location readings are recorded in a &lt;a href="http://en.wikipedia.org/wiki/Unix_time"&gt;&lt;span class="caps"&gt;POSIX&lt;/span&gt; time&lt;/a&gt; and have not been adjusted by time zone, so they are still in the &lt;a href="http://en.wikipedia.org/wiki/Coordinated_Universal_Time"&gt;&lt;span class="caps"&gt;UTC&lt;/span&gt;&lt;/a&gt; time zone. This means that they are 8 hours off from the actual time in California, where I usually am. This doesn&amp;#8217;t bother me too much at the moment because the visualization is still relatively low resolution in the time domain anyways. At some point I might implement the relevant transformation, but this will raise its own issues because I won&amp;#8217;t &lt;em&gt;always&lt;/em&gt; be in California, not to mention all that Daylight Savings nonsense.
-   [Click here for an addendum to this post that will take you through how to schedule the &lt;span class="caps"&gt;EC2&lt;/span&gt; instance and avoid having it run&amp;nbsp;24/7][]&lt;/p&gt;
&lt;p&gt;[Click here for an addendum to this post that will take you through
  how to schedule the &lt;span class="caps"&gt;EC2&lt;/span&gt; instance and avoid having it run 24/7]: http://www.spencerboucher.com/ec2-apis/
    &amp;#8220;Scheduling tasks in the cloud with &lt;span class="caps"&gt;EC2&lt;/span&gt;&amp;nbsp;APIs&amp;#8221;&lt;/p&gt;</summary><category term="api"></category><category term="aws"></category><category term="cartoDB"></category><category term="cartography"></category><category term="cron"></category><category term="ec2"></category><category term="map"></category><category term="quantifiedSelf"></category></entry><entry><title>Luke attempts a novel analysis in SAS</title><link href="http://justmytwospence.github.com/pelican/luke-skywalker-attempts-a-novel-analysis-in-sas.html" rel="alternate"></link><updated>2014-01-06T22:17:00+01:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2014-01-06:luke-skywalker-attempts-a-novel-analysis-in-sas.html</id><summary type="html"></summary><category term="SAS"></category><category term="R"></category></entry><entry><title>Luke Skywalker on SAS</title><link href="http://justmytwospence.github.com/pelican/luke-skywalker-on-sas.html" rel="alternate"></link><updated>2013-12-09T00:24:00+01:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2013-12-09:luke-skywalker-on-sas.html</id><summary type="html"></summary><category term="SAS"></category><category term="R"></category></entry><entry><title>Kaggle(esque)</title><link href="http://justmytwospence.github.com/pelican/kaggle-esque.html" rel="alternate"></link><updated>2013-12-07T06:38:00+01:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2013-12-07:kaggle-esque.html</id><summary type="html">&lt;p&gt;Our program hosted its own Kaggle-style competition this quarter, featuring a “mystery” dataset with a binary target variable. I was impressed by the reveal.js javascript library, so I put together our final slides using it, both because its pretty, and as a way to get some more practice with &lt;span class="caps"&gt;HTML&lt;/span&gt;, &lt;span class="caps"&gt;CSS&lt;/span&gt;, and javascript. On top of that, I had to expand my knowledge of Git in order to publish it on their GitHub Pages platform, so wins all around. Check out the work of Team LoanShark&amp;nbsp;here:&lt;/p&gt;
&lt;iframe src="http://justmytwospence.github.io/LoanSharks/slides/#/" width="100%" height="500"&gt;
Your browser doesn&amp;#8217;t support iframes. Do yourself a favor and go
download a *real* browser
&lt;/iframe&gt;</summary><category term="javascript"></category><category term="reveal.js"></category></entry><entry><title>Map-time at Stamen</title><link href="http://justmytwospence.github.com/pelican/map-time-at-stamen.html" rel="alternate"></link><updated>2013-12-01T02:37:00+01:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2013-12-01:map-time-at-stamen.html</id><summary type="html">&lt;p&gt;Last week, a classmate and I took a break from coursework to attend one of the many great Meetup events that San Francisco has to offer for data science practitioners. I’ve been pushing myself to attend at least one data-centric Meetup every week, because these events are one of the most amazing parts about going to school in the same place where so many of the biggest names work. To be honest, I believe that becoming a presence in the data science scene and meeting the movers and shakers is equally if not more important than&amp;nbsp;coursework.&lt;/p&gt;
&lt;p&gt;I actually attended 3 meetups last week, one about D3.js at Trulia &lt;span class="caps"&gt;HQ&lt;/span&gt;, one about &lt;span class="caps"&gt;GIS&lt;/span&gt; technologies and the Code for America &lt;span class="caps"&gt;HQ&lt;/span&gt;, and one about mapping at Stamen &lt;span class="caps"&gt;HQ&lt;/span&gt;. I picked all three because they are relevant to a geospatial data visualization that I am working on for my practicum at AutoGrid, but the last one is what I’m going to talk a bit about, because it was the most&amp;nbsp;hands-on.&lt;/p&gt;
&lt;p&gt;The workshop took place at Stamen Design’s headquarters in the Mission and was led by Eric Theise; you can see his beautiful/informative slides (created using &lt;a href="http://lab.hakim.se/reveal-js/#/"&gt;reveal.js&lt;/a&gt;) here:   &lt;a href="http://erictheise.com/maptime_platform_slides/#/"&gt;&lt;/a&gt;&lt;a href="http://erictheise.com/maptime_platform_slides/#/"&gt;http://erictheise.com/maptime_platform_slides/#/&lt;/a&gt;   &lt;/a&gt;   Some useful Q&amp;amp;A happened on the Meetup event page as well:   &lt;a href="http://www.meetup.com/Maptime-SF/events/147110652/"&gt;&lt;/a&gt;&lt;a href="http://www.meetup.com/Maptime-SF/events/147110652/"&gt;http://www.meetup.com/Maptime-&lt;span class="caps"&gt;SF&lt;/span&gt;/events/147110652/&lt;/a&gt;   &lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This was actually a two-part workshop, but it was relatively painless to follow the instructions and get up to speed for the part &lt;span class="caps"&gt;II&lt;/span&gt;, so you should really give it a shot even now if it looks&amp;nbsp;interesting.&lt;/p&gt;
&lt;p&gt;First we got postgres up and running on our machines. I have local installations of MySQL, MongoDB, Hadoop and Hive up and running thanks to our course in Distributed Databases, but our class didn’t have time to get to postgres within a single credit hour. This, despite the fact that our professor admits to postgres being the best database to use if you have anything to say about&amp;nbsp;it.&lt;/p&gt;
&lt;p&gt;Next, we populated our database with some data from OpenStreetMap. Mike Migurski extracts data from &lt;span class="caps"&gt;OSM&lt;/span&gt; for major metropolitan areas on a semi-regular basis, so we used the San Francisco data &lt;a href="http://metro.teczno.com/#san-francisco"&gt;available on his web site&lt;/a&gt; via &lt;a href="http://wiki.openstreetmap.org/wiki/Osm2pgsql"&gt;osm2pgsql&lt;/a&gt;, a command-line utility that loads OpenStreetMap data into PostgreSQL&amp;nbsp;databases.&lt;/p&gt;
&lt;p&gt;Then we used &lt;a href="https://www.mapbox.com/tilemill/"&gt;TileMill&lt;/a&gt;, MapBox’s desktop application, to visualize our newborn database. We discovered how remarkably easy it can be to create vector layers for data contained in such a postGIS database using the same old &lt;span class="caps"&gt;SQL&lt;/span&gt; and &lt;span class="caps"&gt;CSS&lt;/span&gt; syntax you already know and love. Eric introduced us to some sensible pre-baked &lt;a href="https://github.com/gravitystorm/openstreetmap-carto"&gt;CartoCSS boilerplate&lt;/a&gt; courtesy of Andy&amp;nbsp;Allen.&lt;/p&gt;
&lt;p&gt;Lastly, we used a nifty feature of TileMill to actually bake our own map tiles and serve them up for use in our own maps. Note that if you want to do this, you’ll need the &lt;a href="https://github.com/mapbox/mbutil"&gt;mbutil command-line utility&lt;/a&gt;, not currently mentioned in the slide&amp;nbsp;deck.&lt;/p&gt;
&lt;p&gt;Not too shabby for 2 hours on a Wednesday night. Many thanks to the guys at Stamen for hosting, especially Eric for all his work on the slides. Not to mention the many other brilliant people who have made the tools and resources that allow something this involved and grandiose to be done on a laptop by someone who is still learning the ropes. Hands-on workshops like this are one of the best ways to learn these technologies. Case in point, I may not have ever stumbled across Mike or Andy’s resources had I not been learning directly from people who are intimately familiar with the practical ins and outs of digital&amp;nbsp;cartography.&lt;/p&gt;
&lt;p&gt;Digital mapping is rapidly capturing my interest because of the beautifully functional things one can do with it, and it seems like an amazing time to be learning it, because the ecosystem is beginning to really flourish. Looking forward to more&amp;nbsp;events!&lt;/p&gt;</summary><category term="cartography"></category><category term="maps"></category></entry><entry><title>StepLively update</title><link href="http://justmytwospence.github.com/pelican/steplively-update.html" rel="alternate"></link><updated>2013-11-03T21:59:00+01:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2013-11-03:steplively-update.html</id><summary type="html">&lt;p&gt;This week I got an email from RStudio letting me know that after a week or two of waiting, I’ve been assigned &lt;span class="caps"&gt;2GB&lt;/span&gt; of space on their servers for hosting Shiny apps. So now you can click on the above link to see the live version of my stepwise regression app that I posted last week. In celebration, I’ve added a few extras to the app, including the ability to upload your own data set, although its not a particularly robust feature&amp;nbsp;yet.&lt;/p&gt;
&lt;p&gt;Update: I’ve recently moved to Rstudio’s next-gen hosting platform: shinyapps.io. This was necessary because I was having issues installing low-level packages like Rcpp onto their Spark server. This new platform is much more flexible in this regard. I’ve updated links&amp;nbsp;accordingly.&lt;/p&gt;</summary><category term="R"></category><category term="Shiny"></category><category term="stepwise"></category></entry><entry><title>Peeking into a black box</title><link href="http://justmytwospence.github.com/pelican/peeking-into-a-black-box.html" rel="alternate"></link><updated>2013-10-22T23:59:00+02:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2013-10-22:peeking-into-a-black-box.html</id><summary type="html">&lt;p&gt;I’ve been meaning to try my hand at Shiny for a while now, and I’ve finally gotten around to it. Shiny is an R package from the people who brought you RStudio that allows you to take R code and embed it within an interactive &lt;span class="caps"&gt;HTML&lt;/span&gt; &lt;span class="caps"&gt;UI&lt;/span&gt; that uses Bootstrap styling. You can get surprising mileage out of R visualization when it magically animates (I would have named the package “pinocchio” but they didn’t ask me). &lt;a href="http://www.rstudio.com/shiny/showcase/"&gt;Check out the Shiny showcase if you don’t believe&amp;nbsp;me.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;My original idea to get my feet wet was a real-time visualization of least-angle regression, because I’m fascinated by how it turns a discrete algorithm like step-wise regression into an analogue algorithm (or at least an approximation of one). I think it would be neat to watch this analogue “dialing in” of regression&amp;nbsp;coefficients.&lt;/p&gt;
&lt;p&gt;Making that happen would require ripping apart the code in the &lt;span class="caps"&gt;LARS&lt;/span&gt; package. I wasn’t feeling quite that ambitious considering a few other looming assignments, but the fact that its even an option for me to explore in the future is one of the beautiful features of an open source language like R. Ultimately I settled on visualizing a plain vanilla forward stepwise regression, because I had a home-brew implementation lying around from a previous&amp;nbsp;assignment.&lt;/p&gt;
&lt;p&gt;Without further ado, here’s a preview in .gif format:[hr]&lt;img alt="" src="http://media.tumblr.com/66066fffc66745aa8b9047b5e49032d3/tumblr_inline_mv3h49xMTG1r0kwho.gif" /&gt;[hr]You can run the actual app for yourself in your R console with only three lines of code (two if you already have shiny&amp;nbsp;installed!) &lt;/p&gt;
&lt;p&gt;​1. install.packages(‘shiny’)
2. library(shiny)
3. runGitHub(‘shiny_stepwise’,&amp;nbsp;‘justmytwospence’)&lt;/p&gt;
&lt;p&gt;The ability to run anyone’s shiny app straight from their GitHub profile is super cool. You can see the source code on my GitHub as well. Once I hear back from the RStudio folks about getting in on the beta version of their web hosting service, I can try to make it available to people who don’t have R installed (but really, will anyone who cares about stepwise regression &lt;em&gt;not&lt;/em&gt; have R&amp;nbsp;installed?).&lt;/p&gt;
&lt;p&gt;I think its actually a pretty cool glimpse into an algorithm that is (justifiably) distrusted by many for being too opaque. I’ll continue adding functionality and hopefully it will useful for someone other than myself in the not too distant future; either as a simple learning demonstration or maybe even in an actual modeling context. I will definitely be making more Shiny apps in the future as I become more familiar with its advanced features. Building dashboards, as I am discovering, can be quite&amp;nbsp;addicting.&lt;/p&gt;
&lt;p&gt;&lt;span class="caps"&gt;EDIT&lt;/span&gt;: The app is now live! See it at &lt;a href="http://steplively.spencerboucher.com"&gt;http://justmytwospence.shinyapps.io/StepLively/&lt;/a&gt;&lt;/p&gt;</summary><category term="R"></category><category term="Shiny"></category><category term="stepwise"></category></entry><entry><title>Switching R versions on-the-fly</title><link href="http://justmytwospence.github.com/pelican/switching-r-versions-on-the-fly.html" rel="alternate"></link><updated>2013-10-22T22:01:00+02:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2013-10-22:switching-r-versions-on-the-fly.html</id><summary type="html">&lt;p&gt;If you need to switch back to an older version of R to use a particular package, it doesn’t get easier than downloading the &lt;a href="http://r.research.att.com/"&gt;RSwitcher utility from &lt;span class="caps"&gt;AT&lt;/span&gt;&amp;amp;T&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I use homebrew to keep my main installation up-to-date, and then switching back to 2.7 when I need a certain package is as easy as one&amp;nbsp;click.&lt;/p&gt;</summary><category term="R"></category></entry><entry><title>Holo color palette</title><link href="http://justmytwospence.github.com/pelican/holo-color-palette.html" rel="alternate"></link><updated>2013-08-20T06:19:00+02:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2013-08-20:holo-color-palette.html</id><summary type="html">&lt;p&gt;Despite being slightly colorblind, I’m one of those
people who is bizarrely anal-retentive when it comes to color-schemes in
the software that I use. I use custom &lt;span class="caps"&gt;CSS&lt;/span&gt; extensions in Chrome to make
the color schemes of websites like Wikipedia, Youtube, etc a bit more
pleasing. I did some digging in the accessibility preference pane of
Adobe Reader to make the default document background a nice book-like
sepia tone which makes reading PDFs online a much less straining
endeavor (incidentally - Google Play Books &lt;em&gt;only&lt;/em&gt; has a white background
which is why I greatly prefer the Amazon Kindle web app). I’ve spent
wayy too long (as I think many geeks do), customizing my terminal and
custom android &lt;span class="caps"&gt;ROM&lt;/span&gt; themes. I think you get the&amp;nbsp;picture.&lt;/p&gt;
&lt;p&gt;Anyways, I had been using the Solarized palette for a lot of things
because it seems like its choices are a bit less arbitrary and has some
science behind it (although I haven’t done any research into how
legitimate that science is). Its a bit limiting, however, and recently
I’ve been attracted to the Holo color palette that &lt;span class="caps"&gt;ICS&lt;/span&gt; compliant Android
apps use. I couldn’t find a pre-compiled Holo palette in .clr format for
use in the Mac &lt;span class="caps"&gt;OSX&lt;/span&gt; Color Picker utility, so I made a simple, bare-bones
one. First I had to download the &lt;span class="caps"&gt;HEX&lt;/span&gt; plugin from &lt;a href="http://wafflesoftware.net/hexpicker/"&gt;wafflesoftware.net&lt;/a&gt;
which for some strange reason is not a functionality that Apple thought
worthwhile to put into a color picker (???). &lt;a href="http://db.tt/xU7lyIBh"&gt;You can download my .clr
palette right here&lt;/a&gt;. Maybe I can save the next anal-retentive googler
a few&amp;nbsp;minutes.&lt;/p&gt;
&lt;p&gt;&lt;span class="caps"&gt;PS&lt;/span&gt;. While I am talking about color - if you haven’t heard of &lt;a href="http://justgetflux.com/"&gt;fl.ux&lt;/a&gt;,
check it out. It is a magical little utility that warms the color of
your screen automatically after sunset and can &lt;em&gt;really&lt;/em&gt; save your eyes
and make getting to sleep a little bit easier if you are working in
front of your screen late at&amp;nbsp;night.&lt;/p&gt;</summary><category term="color"></category><category term="holo"></category><category term="solarized"></category></entry><entry><title>Twitter Reaction to Events Often at Odds with Overall Public Opinion</title><link href="http://justmytwospence.github.com/pelican/twitter-reaction-to-events-often-at-odds-with-overall.html" rel="alternate"></link><updated>2013-08-06T00:09:00+02:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2013-08-06:twitter-reaction-to-events-often-at-odds-with-overall.html</id><summary type="html">&lt;p&gt;[Twitter Reaction to Events Often at Odds with Overall Public&amp;nbsp;Opinion][]&lt;/p&gt;
&lt;p&gt;This is a long-standing beef that I have always had with any Twitter-sentiment analysis. A huge chunk of people tweeting are just whiny adolescents who wouldn’t even be polled if we were to design a huge study. I haven’t heard of any twitter-mining tools or packages that allow you to filter the Twitterers that you are pulling your random sample of tweets from. That would certainly be worthwhile and would make a lot of people care a lot more about Twitter sentiment&amp;nbsp;analyses.&lt;/p&gt;
&lt;p&gt;[Twitter Reaction to Events Often at Odds with Overall Public
  Opinion]:&amp;nbsp;http://www.pewresearch.org/2013/03/04/twitter-reaction-to-events-often-at-odds-with-overall-public-opinion/&lt;/p&gt;</summary></entry><entry><title>On being approximate</title><link href="http://justmytwospence.github.com/pelican/on-being-approximate-an-inadvertent-data-poem.html" rel="alternate"></link><updated>2013-07-20T05:39:00+02:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2013-07-20:on-being-approximate-an-inadvertent-data-poem.html</id><summary type="html">&lt;p&gt;&lt;img alt="An inadvertent data poem" src="http://justmytwospence.github.com/pelican/images/on-being-approximate.png" /&gt;&lt;/p&gt;
&lt;p&gt;An inadvertent data poem by &lt;a href="http://www.usfca.edu/facultydetails.aspx?id=6442485442"&gt;Dr. Cindi&amp;nbsp;Thompson&lt;/a&gt;&lt;/p&gt;</summary><category term="approximation"></category></entry><entry><title>D3 Test</title><link href="http://justmytwospence.github.com/pelican/d3-test.html" rel="alternate"></link><updated>2013-03-21T00:00:00+01:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2013-03-21:d3-test.html</id><summary type="html">

	&lt;button id="add" class="btn btn-info"&gt;
		Add
	&lt;/button&gt;
	&lt;button id="remove" class="btn btn-info"&gt;
		Remove
	&lt;/button&gt;

	&lt;div id="svg"&gt;&lt;/div&gt;

</summary></entry><entry><title>An overlooked super-power</title><link href="http://justmytwospence.github.com/pelican/sound.html" rel="alternate"></link><updated>2012-09-06T01:56:00+02:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2012-09-06:sound.html</id><summary type="html">&lt;p&gt;&lt;img alt="" src="http://media.tumblr.com/tumblr_m9wn34HSk21r0kwho.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;Have you ever thought of what a ridiculous superpower the ability to speak is? If I want somebody else to know something, I don’t have to wait until that idea pops into their head (the likelihood of which approaches zero). I can actually &lt;strong&gt;&lt;em&gt;put&lt;/em&gt;&lt;/strong&gt; it there. But there is no way to transfer the pattern of action potentials in my brain’s wiring directly into someone else’s wiring because our brains are simply too important to not be 100% encased in protective skull. And make no mistake, thats exactly what you are doing when you talk to someone: you are changing the way their brain is firing, which is nothing less than &lt;strong&gt;&lt;em&gt;who they are&lt;/em&gt;&lt;/strong&gt; at the most fundamental and meaningful&amp;nbsp;level.&lt;/p&gt;
&lt;p&gt;Not only that, I don’t even have to be able to see them or be anywhere &lt;strong&gt;&lt;em&gt;near&lt;/em&gt;&lt;/strong&gt; them to do so. I take the enormous complexity of information that is making up my thoughts (who I &lt;strong&gt;&lt;em&gt;am&lt;/em&gt;&lt;/strong&gt;) and succinctly encode it in a pattern of vibration. I can then simply &lt;strong&gt;&lt;em&gt;will&lt;/em&gt;&lt;/strong&gt; the air molecules 200 feet away to vibrate in accordance with the pattern that represents my state of being. That part is incredible. I can simply cause a piece of nature that contains no information to be saturated with information from huge distances. Mind.&amp;nbsp;Blown.&lt;/p&gt;
&lt;p&gt;As if that wasn’t enough, the receiver of that information gets a boat-load of &lt;strong&gt;&lt;em&gt;meta&lt;/em&gt;&lt;/strong&gt; information where the source of that information is in physical space &lt;strong&gt;&lt;em&gt;despite&lt;/em&gt;&lt;/strong&gt; the fact that she only has access to the air molecules within an inch or two of her&amp;nbsp;head.&lt;/p&gt;</summary><category term="brain"></category><category term="power"></category><category term="science"></category><category term="sound"></category><category term="super"></category><category term="superpower"></category></entry><entry><title>Keeping It Real</title><link href="http://justmytwospence.github.com/pelican/keeping-it-real.html" rel="alternate"></link><updated>2012-01-06T05:11:00+01:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2012-01-06:keeping-it-real.html</id><summary type="html">&lt;p&gt;&lt;img alt="" src="http://media.tumblr.com/tumblr_lxd2ephtCm1r0kwho.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;Today I was listening to a Freakonomics podcast about prediction and how monumentally terrible we are at it- even experts. The segment featured some small European country that had passed a law to fine or imprison psychics whose predictions were wrong. Why maintain such strict  standards for their predictions when we don’t hold anyone else similarly accountable. In all honesty I’m not sure I wouldn’t be in favor of such a law because such psychics are making the claim that they are delivering a service that they are demonstrably &lt;em&gt;not&lt;/em&gt; providing (i.e. &lt;em&gt;fraud&lt;/em&gt;), but that’s besides the&amp;nbsp;point.&lt;/p&gt;
&lt;p&gt;The point is that it got me thinking about accountability for predictions. They are everywhere, obviously. Pundits, politicians, financial speculators (oh my)… We have fact checking organizations that (to arguable degrees of success) provide a way of holding these people to their claims about the past and present. Obviously we couldn’t rightly hold these people’s predictions to the same standard that we do (or often don’t) when they are reciting facts, but &lt;strong&gt;&lt;em&gt;why the hell aren’t we keeping a track record&lt;/em&gt;&lt;/strong&gt;?&lt;/p&gt;
&lt;p&gt;What if every time a president, congressman, political pundit, Fed chairman, or otherwise high-profile “expert” made a prediction, we entered it into a database? What if we actually kept statistics on how often there predictions panned out? Right now all the incentives are stacked to encourage wanton prediction-making, because we only keep track of the &lt;em&gt;hits&lt;/em&gt;, and not the &lt;em&gt;misses&lt;/em&gt;. Why? Because right now we are effectively letting the people who are making the predictions be the ones who keep track of their success by &lt;em&gt;not calling them out&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;If we switched the incentives around, its a game changer. First, experts become more careful with their predictions, improving their quality overall (because face it, right now they are almost always less than worthless). Second, we the public get an idea of whose predictions are actually worth listening to. I shudder (and then smile a bit) to think about how many careers would be dashed upon the rocks if the ability to produce this metric came&amp;nbsp;about.&lt;/p&gt;
&lt;p&gt;I picture a website - freely available to all - maybe with individual profiles for all the would-be Nostradomus. Maybe a staff of statisticians would have to keep track of all the predictions made, and users could suggest new profiles they would like to see added and monitored. Picture Mint.com, but predictions instead of transactions. For example, you could search Glenn Beck’s predictions by category, by time-frame, or by outcome (yes, no, partial?), and get awesome graphs and pie charts and a big ‘ole “percentage correct” next to your&amp;nbsp;name. &lt;/p&gt;
&lt;p&gt;Thoughts?&lt;/p&gt;
&lt;p&gt;&lt;span class="caps"&gt;EDIT&lt;/span&gt;: [Lacking the ability to actually build such a platform, I threw together a google spreadsheet with some of the basic functionality. Obviously this won’t really be useful unless a lot of people were to use it, but hey it might as well exist. Click this paragraph to go to it and&amp;nbsp;contribute!][] &lt;/p&gt;
&lt;p&gt;[Lacking the ability to actually build such a platform, I threw
  together a google spreadsheet with some of the basic functionality.
  Obviously this won’t really be useful unless a lot of people were to
  use it, but hey it might as well exist. Click this paragraph to go to
  it and contribute!]:&amp;nbsp;https://docs.google.com/spreadsheet/viewform?hl=en_US&amp;amp;formkey=dDdCaWtTSWZQT1VRbEM2QkNSR2RhNGc6MQ#gid=0&lt;/p&gt;</summary><category term="economics"></category><category term="freakonomics"></category><category term="politics"></category><category term="prediction"></category><category term="predictions"></category></entry><entry><title>Open Sesame?</title><link href="http://justmytwospence.github.com/pelican/open-sesame.html" rel="alternate"></link><updated>2012-01-01T01:18:00+01:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2012-01-01:open-sesame.html</id><summary type="html">&lt;p&gt;Well its been ages since I wrote a blog post and this thought has been on my mind for a long time. Passwords. What the&amp;nbsp;hell? &lt;/p&gt;
&lt;p&gt;I don’t know when “Ali Baba and the 40 Thieves” is supposed to take place, but it was a &lt;em&gt;long time ago&lt;/em&gt;. What does it say about us that we are using &lt;em&gt;exactly&lt;/em&gt; the same authentication system thousands of years&amp;nbsp;later?&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://media.tumblr.com/tumblr_lx3if8FDIG1r0kwho.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;Passwords are just archaic. They are pretty poor performers at both ends of what they are supposed to do. For intended users, they are inconvenient because they are so easy to forget. For intruders, they are usually remarkably easy to guess or otherwise acquire. &lt;em&gt;Especially&lt;/em&gt; with the brute force afforded these intruders by modern&amp;nbsp;technology.&lt;/p&gt;
&lt;p&gt;I find it shocking that in all of human history we hadn’t devised anything better until biometrics came about. Equally shocking is that we still haven’t made the switch to biometrics as a society. I wonder how much money is lost each year due to issues that could have been avoided with a better authentication&amp;nbsp;system.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://media.tumblr.com/tumblr_lx3ifmIQHT1r0kwho.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;I’m going to brainstorm alternative paradigms that could have been implemented in between passwords and biometrics- I’ll post here if and when I think of any.  Leave a comment (does this blog have a readership?) if you can think of one. Also leave a comment if you know why the adoption of biometrics has been so&amp;nbsp;slow.&lt;/p&gt;
&lt;p&gt;This makes me wonder- what other systems are we living with that were designed for an ancient world that we no longer live&amp;nbsp;in…&lt;/p&gt;
&lt;p&gt;&lt;span class="caps"&gt;EDIT&lt;/span&gt;: I posted this exact question to Quora, and received a &lt;span class="caps"&gt;TON&lt;/span&gt; of profound answers. &lt;a href="http://www.quora.com/What-are-some-systems-we-live-with-today-that-were-designed-for-a-world-of-the-past"&gt;Check it out here!&lt;/a&gt; (33 answers and counting! Plus it got&amp;nbsp;“best-sourced”).&lt;/p&gt;</summary><category term="biometrics"></category><category term="passwords"></category><category term="technology"></category></entry><entry><title>The new face of education</title><link href="http://justmytwospence.github.com/pelican/the-new-face-of-education.html" rel="alternate"></link><updated>2011-11-19T21:45:00+01:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2011-11-19:the-new-face-of-education.html</id><summary type="html">&lt;p&gt;We are on the brink of one of the most radical paradigm shifts to affect human society in millennia. &lt;span class="caps"&gt;OK&lt;/span&gt;, maybe that that sounds obvious to a lot of people what with the explosion of innovation that the internet and other new technologies over the past decade or two. But I’m talking about a total revamping of an institution that has existed as long as language has existed- indeed, as long as &lt;em&gt;we&lt;/em&gt;have existed:&amp;nbsp;education.&lt;/p&gt;
&lt;p&gt;Education has barely changed one iota in the last thousand years of its practice. Plato and Socrates taught their classes essentially the &lt;em&gt;same way&lt;/em&gt; that a modern philosophy or science class is taught - hell, we still use the &lt;em&gt;Socratic method&lt;/em&gt; in modern classes (this isn’t a claim that the method is ineffective, merely a demonstration of how long current practices have existed without drastic change). Dozens of students congregate where the one who has the knowledge is located, and this one knowledgable person teaches a concept to the students and answers questions. The only change in the late 1900s was that there were significantly more places where this happened - called&amp;nbsp;colleges/universities.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://media.tumblr.com/tumblr_lux6c2LeEa1r0kwho.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;But colleges/universities were designed in an ancient world. They were built to spread knowledge in an era of very few knowledgable people relative to the entire population, when the most efficient way - and indeed the &lt;em&gt;only&lt;/em&gt;way - of conducting this transfer of knowledge was face-to-face. This is no longer the world that we live in. Courtesy of modern technology, we live in a globally connected world with accessible experts in any field you’d care to study, and I don’t think that modern institutions of higher learning will survive the shift. At least not in a state that anywhere near resembles the way they operate&amp;nbsp;now.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://media.tumblr.com/tumblr_lux6czF6On1r0kwho.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exhibit&amp;nbsp;A&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;If you want to get an idea of what the new face of eduction will be like, look to Stanford University, the bleeding edge of the move toward the new&amp;nbsp;system. &lt;/p&gt;
&lt;p&gt;This semester, two Stanford-level courses were made available &lt;em&gt;for free&lt;/em&gt; to &lt;em&gt;anyone&lt;/em&gt; with an internet connection: Introduction to Artificial Intelligence and Machine Learning. These courses were taught by some of the biggest names in the field. Andrew Ng and his team created the Machine Learning course, which is the one that I am currently enrolled in, so its the one I’ll talk&amp;nbsp;about.&lt;/p&gt;
&lt;p&gt;Over 65,000 students are enrolled. &lt;a href=""&gt;Here’s a map showing a little cross-section of where they come from&lt;/a&gt; (spoiler alert- its &lt;em&gt;everywhere&lt;/em&gt;). Skimming the extensive “introductions” section of the class forum reveals that these students are incredibly diverse, from software engineer professionals working here in silicon valley to high school students in poor eastern European communities and absolutely everything in&amp;nbsp;between. &lt;/p&gt;
&lt;p&gt;Online courses in and of themselves are not particularly new- institutions such as &lt;a href="http://ocw.mit.edu/index.htm"&gt;&lt;span class="caps"&gt;MIT&lt;/span&gt;&lt;/a&gt;, &lt;a href="http://webcast.berkeley.edu/"&gt;Berkeley&lt;/a&gt;, &lt;a href="http://oyc.yale.edu/"&gt;Yale&lt;/a&gt;, and many other traditionally well known schools have been making lectures and course materials available online for years. The key difference is that this new wave of online courses are designed specifically and exclusively for the new global audience. This is immediately apparent in the presentation of the lectures, the format of the homework assignments, and the design of the curriculum. The result is a learning experience that I argue rivals that of any traditional college&amp;nbsp;course. &lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://media.tumblr.com/tumblr_luxge4HuZN1r0kwho.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;The homework assignments for Ng’s class include quizzes that solidify the students intuition of the concept, combined with specific programming problem sets that gives the student a handle on concrete implementation of the ideas using Octave (a freeware version of &lt;span class="caps"&gt;MATLAB&lt;/span&gt;). As someone who has taken similar &lt;span class="caps"&gt;MATLAB&lt;/span&gt; courses at a well known private university, I can confidently attest to the relative efficacy of the new&amp;nbsp;format.&lt;/p&gt;
&lt;p&gt;There are differences of course. To clear up misunderstandings that I have, I used to go to a review session- usually led by a &lt;span class="caps"&gt;TA&lt;/span&gt;- who would try to answer the questions of dozens of students within a few hours. Now- I simply post a question to the class forum and have it answered &lt;em&gt;very&lt;/em&gt;quickly by up to dozens of knowledgable practitioners- many of whom are already implementing similar programming techniques in their line of&amp;nbsp;work.&lt;/p&gt;
&lt;p&gt;Another significant difference is that instead of 200 different lecturers teaching the same topic to 65,000 learners, we have 1. This may strike some as a disadvantage- but in the future, this system will allow the best lecturers to float to the top. Think about how much more cost effective this is- if we replace 200 lecturers with 1, we are cutting the costs of education by a factor of hundreds, not to mention drastically expanding the number of students we can&amp;nbsp;reach.&lt;/p&gt;
&lt;p&gt;Note that in the above point I mention only &lt;em&gt;lecturers,&lt;/em&gt;not &lt;em&gt;teachers.&lt;/em&gt;What I believe we will see is a simultaneous centralization of certain aspects of education and decentralization of others. In an increasingly connected world, everyone becomes a teacher. Are you a computer programmer? You are also going to be a programming teacher. Are you a marketing analyst? Guess what, you are also going to be a teacher of marketing. In a way that seems contradictory at first- this consolidation of our currently bloated educational system will provide the infrastructure necessary to bring back peer-to-peer transfer of&amp;nbsp;knowledge.&lt;/p&gt;
&lt;p&gt;Stanford is expanding their open courses next semester, and my prediction is that it only gets bigger from here.  Below is a list of the next classes to be offered (still trying to decide which ones I will have the time to participate in!). I highly recommend them to everyone who is at all&amp;nbsp;interested.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;img alt="" src="http://media.tumblr.com/tumblr_lux62tK2sp1r0kwho.jpg" /&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The role of the university will have to change dramatically if and when such a system becomes the norm. One key role they will have to play lies in accreditation. (At least for now) students enrolled in these Education2.0 courses do so merely for the knowledge gained. There is no course credit gained which is a double edged sword. On the one hand, it means students are that much more collaborative. Cheating becomes a non-issue in such an environment. The key question becomes how to decide which students are qualified for a given job, etc. Instead of having accreditation agencies give the seal of approval to other institutions who then parcel out degrees, we might see a move toward tests or other processes to directly accreditate&amp;nbsp;individuals.&lt;/p&gt;
&lt;p&gt;I could continue to wildly speculate on the issue and I have lots more ideas about how things might pan out (future blog topics might include how &lt;a href="http://www.khanacademy.org/"&gt;Khan Academy&lt;/a&gt; is turning primary school education on its head, or how studio schools and apprenticeship systems are on the rise as well). If you disagree or would like to point out how any of these particular ideas are crazy, leave a comment! Please! All that I do know is that with tuition prices rising &lt;em&gt;outrageously&lt;/em&gt; every year while wonderful free alternative options begin to proliferate, &lt;strong&gt;something’s gotta&amp;nbsp;give.&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nl"&gt;http:&lt;/span&gt;&lt;span class="c1"&gt;//maps.google.com/maps/ms?ie=UTF&amp;amp;msa=0&amp;amp;msid=203716810039202316490.0004aeb1b1a01b1d3b9af&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</summary><category term="andrew ng"></category><category term="college"></category><category term="education"></category><category term="higher education"></category><category term="machine learning"></category><category term="stanford"></category><category term="university"></category></entry><entry><title>Brainssssss</title><link href="http://justmytwospence.github.com/pelican/brainssssss.html" rel="alternate"></link><updated>2011-11-07T06:50:00+01:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2011-11-07:brainssssss.html</id><summary type="html">&lt;p&gt;&lt;a href="http://www.stanfordesp.org/"&gt;&lt;span class="caps"&gt;SPLASH&lt;/span&gt;&lt;/a&gt; is an awesome educational program that started at &lt;span class="caps"&gt;MIT&lt;/span&gt; and has spread to a few other schools including Stanford. Basically, high school students in the area flock to the main academic quad for one weekend each semester to get a taste of higher education. An extra push is made to recruited underserved populations, but over 2,000 students in total showed up this year. Anyone associated with Stanford can create their own class on &lt;span class="caps"&gt;ANY&lt;/span&gt; topic and make it available for kids to register in (over 200 teachers this year&amp;nbsp;too!).&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://media.tumblr.com/tumblr_lua38m4Ez81r0kwho.gif" /&gt;&lt;/p&gt;
&lt;p&gt;About a month ago the topic of &lt;span class="caps"&gt;SPLASH&lt;/span&gt; came up in one of our weekly lab meetings. Its a great (if somewhat sneaky) way for us to recruit new control subjects because the students are the perfect age for our pediatric studies. We just have to get the kids psyched enough to pester their parents to the point that they contact us. Our lab has taught classes in previous years on neuroimaging, etc. and gotten a few recruits out of&amp;nbsp;it.&lt;/p&gt;
&lt;p&gt;A coworker and I were brainstorming class ideas when we hit upon a sure winner- “Brainssssss: The Neuroscience of Zombies.”  &lt;span class="caps"&gt;SPLASH&lt;/span&gt; took place over Halloween weekend this year after all, and we thought it would be the perfect way to walk the fine line between being fun and interesting enough to keep kids excited and being academically legitimate enough to take&amp;nbsp;seriously.&lt;/p&gt;
&lt;p&gt;The class was way fun to plan and even more fun to teach. I managed to get in touch with the neuroanatomy &lt;span class="caps"&gt;TA&lt;/span&gt; in the medical school, who hooked us up with some preserved human brains- one full brain, one hemisphere, one set of coronal slices, a segment of spinal cord, and some dura matter too. It was surprising how easily we procured them! No background check or signing of papers, just a few emails and an explanation of how to keep them moist and always use gloves before we were sent on our way with two buckets full of brains (very subtly labelled “Whole Brain”). We got them a week early, so they were a huge hit with everyone in our lab. It was interesting how many people who study the brain for a living have never seen one in the flesh (as it were). The first thing anyone seeing a brain for the first time notices is how &lt;em&gt;small&lt;/em&gt; they are. But that mere 3 pounds of meat can learn calculus, predict the future, or even fall in love.&amp;nbsp;Crazy.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://media.tumblr.com/tumblr_lua2yvWFsS1r0kwho.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;Some more emails got me in touch with a guy named Brad Voytek who does research up the peninsula at &lt;span class="caps"&gt;UCSF&lt;/span&gt;. Brad is on the advisory board of the Zombie Research Society and it would appear that we accidentally stumbled upon a phenomenon that is already gaining momentum- the field of zombie research! Check out the &lt;a href="http://zombieresearch.org/home.html"&gt;Zombie Research Society&lt;/a&gt; as well as his personal bog &lt;a href="http://blog.ketyov.com/"&gt;Oscillatory Thoughts&lt;/a&gt;.  The &lt;span class="caps"&gt;ZRS&lt;/span&gt; is simultaneously a fun way to introduce basic neuroscience to a public audience (just as we had thought!), while also poking fun at some of the more questionable aspects of cognitive neuroscience research (eg: look doing X lights up area Y… now we understand X!). Much gratitude for all their&amp;nbsp;assistance!&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://media.tumblr.com/tumblr_lua2yfy1Ee1r0kwho.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;The class itself went great. We had kids brainstorm characteristics of zombies (slow lumbering walk, lack of emotions, insatiable appetite for human flesh, etc.) and then delved into which brain regions would be impaired in order for us to see these specific defecits in behavior. And of course we played Thriller and showed multiple clips from Shaun of the Dead. I think the kids really liked it, and of course you can’t go wrong when you get to show them real&amp;nbsp;brains.&lt;/p&gt;
&lt;p&gt;We signed up for 4 sections of 30 students each, which apparently was way more than the average class size of 5 to 10 students. A scheduling mishap left us with only 3 sections, so we set up in an empty room during the lunch period and I went outside and rounded up another class-worth of kids to make up the difference. Additionally, we were contacted by an administrator to teach our class to some of the parents as a sample &lt;span class="caps"&gt;SPLASH&lt;/span&gt; class. The parents class kind of turned into a Q &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; A session of general neuroscience questions, which was actually really fun. We got some real great questions from kids too: “can zombies get high?” , “would tranquilizers work on zombies?” , and from a tentative girl at the end of class “wait… zombies are&amp;nbsp;real?”&lt;/p&gt;
&lt;p&gt;Overall it was a great success, we got out a lot of fliers, and lots of kids/parents sounded very interested in our research at Stanford. I’m hoping to get more involved with &lt;span class="caps"&gt;SPLASH&lt;/span&gt; at Stanford next&amp;nbsp;semester!&lt;/p&gt;</summary><category term="brain"></category><category term="education"></category><category term="neuroscience"></category><category term="splash"></category><category term="zombies"></category></entry><entry><title>Where science meets sci-fi</title><link href="http://justmytwospence.github.com/pelican/where-science-meets-sci-fi.html" rel="alternate"></link><updated>2011-10-18T04:43:00+02:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2011-10-18:where-science-meets-sci-fi.html</id><summary type="html">&lt;p&gt;Every now and then something comes along that just makes your jaw drop with its sheer brilliance and monumental implications. When that happens in science, it usually feels like you are dropping into a science fiction story, and thats exactly the feeling I got when I listened to Dr. Deisseroth’s talk at one of Stanford’s neuroscience symposiums. It might be old news to many and I did actually already know a bit about the subject, but hearing about this new technology straight from the guy who made it happen and hearing about the directions it’s going in really made me&amp;nbsp;excited.&lt;/p&gt;
&lt;p&gt;Oh, whats this new miracle technology? Optogenics. Its gonna be huge. Trust&amp;nbsp;me.&lt;/p&gt;
&lt;p&gt;Optogenetics is seriously one of the biggest baddest research tools to hit neuroscience research &lt;span class="caps"&gt;EVER&lt;/span&gt;. The implications reach much farther than another new imaging technique (eg like &lt;span class="caps"&gt;EEG&lt;/span&gt;, &lt;span class="caps"&gt;MRI&lt;/span&gt;) and are more along the lines of something like the voltage clamp in the early days of single-cell&amp;nbsp;recording. &lt;/p&gt;
&lt;p&gt;Basically what you can do with optogenetics is selectively genetically modify a subset of neurons by causing them to express protein channels that open/close in response to certain frequencies of light. To a layperson this might not sound impressive until you know that opening these channels is how a neuron actually &lt;em&gt;fires&lt;/em&gt;. So- stated another way- you &lt;span class="caps"&gt;SHINE&lt;/span&gt; &lt;span class="caps"&gt;LIGHT&lt;/span&gt; &lt;span class="caps"&gt;ON&lt;/span&gt; A &lt;span class="caps"&gt;NEURON&lt;/span&gt; &lt;span class="caps"&gt;AND&lt;/span&gt; &lt;span class="caps"&gt;IT&lt;/span&gt; &lt;span class="caps"&gt;TURNS&lt;/span&gt; &lt;span class="caps"&gt;ON&lt;/span&gt;. And this works &lt;span class="caps"&gt;IN&lt;/span&gt; &lt;span class="caps"&gt;VIVO&lt;/span&gt;. In &lt;span class="caps"&gt;MAMMALS&lt;/span&gt;.  All you have to do is wire up some fiber optic cables into the skull. By being strategic in which types of neurons we genetically modify, we can therefore choose to activate specific neural networks with specific goals in&amp;nbsp;mind.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://media.tumblr.com/tumblr_lt8swuV6V21r0kwho.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;This is where things start getting unreal. Since the technology first broke through here at Stanford in 2005, the practical applications have been rolling out. For example, by deactivating reward centers of the brain when when mice are exposed to cocaine, they &lt;span class="caps"&gt;SHOW&lt;/span&gt; &lt;span class="caps"&gt;NO&lt;/span&gt; &lt;span class="caps"&gt;COCAINE&lt;/span&gt; &lt;span class="caps"&gt;PREFERENCE&lt;/span&gt; &lt;span class="caps"&gt;TO&lt;/span&gt; &lt;span class="caps"&gt;WATER&lt;/span&gt;! Normally, mice will eschew absolutely anything in favor of cocaine- including food and water. But with a little light shining on the area (and the correct previous genetic modification) the mice are essentially temporarily cured of cocaine&amp;nbsp;dependence!&lt;/p&gt;
&lt;p&gt;Of course thats over-simplifying things. For example, we are probably actually eliminating the mouse’s desire to experience reward to &lt;span class="caps"&gt;ANY&lt;/span&gt; stimulus at all, so its not exactly a palatable cure. But its fun to picture a future using this technology. What if cocaine addicts could volunteer to have fiber optic cables hooked into &lt;em&gt;their&lt;/em&gt; skull, and just pressed a button whenever they encountered cocaine. The effects are extremely transient- so maybe they could experience pleasure normally until they really really need to be impervious to temptation. Could we do the same for nicotine&amp;nbsp;addicts? &lt;/p&gt;
&lt;p&gt;This is really only the tip of the iceberg.  Researchers have used optogenetic paradigms to make mice &lt;span class="caps"&gt;STOP&lt;/span&gt; in their tracks or &lt;a href="http://www.youtube.com/watch?v=v7uRFVR9BPU"&gt;move in endless circles&lt;/a&gt;, as well as to i[nstantly turn the normally timid creatures into much bolder versions of themselves][].  Both of these particular examples can be particularly scary if applied to humans. A coworker at the same talk painted a rather perplexing scenario as we were walking back. Imagine a dystopian future in which a government vaccinations of all children include a dose of a harmless virus that primes our brains for such light treatment.  Deisseroth hinted that technology for achieving optic stimulation trans-cranially is not too far in the future… What if a police officer had merely to point a laser at someone’s head to have them literally freeze in&amp;nbsp;place? &lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://media.tumblr.com/tumblr_lt8yynOhxX1r0kwho.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;Deisseroth was asked in the Q&amp;amp;A about human applications, but he claimed that his group was excited enough about its current use in animal research that it wasn’t thinking ahead to any form of clinical research or trial. He totally smirked when he was saying it though. A sort of- this is what my lawyer thinks I should say so nobody gets scared- kinda look. Either way- the future is super bright in this area (pun unintended!). It has already won the “method of the year” award for 2010 and I would bet 100 bucks there’s a Nobel Prize in the future for Deisseroth (which is incredible because he is so young!) Its awesome that the origin and hub of this research is here at Stanford. Its definitely something I’d like to look more into- I could see myself going into graduate school to work on&amp;nbsp;this.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://media.tumblr.com/tumblr_lt8yqpZwVj1r0kwho.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;[nstantly turn the normally timid creatures into much bolder versions
  of themselves]:&amp;nbsp;http://vimeo.com/12300587&lt;/p&gt;</summary><category term="neuroscience"></category><category term="optogenetics"></category></entry><entry><title>Science: the art and arborization of knowledge</title><link href="http://justmytwospence.github.com/pelican/science-the-art-and-arborization-of-knowledge.html" rel="alternate"></link><updated>2011-10-06T06:27:00+02:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2011-10-06:science-the-art-and-arborization-of-knowledge.html</id><summary type="html">&lt;p&gt;I often find it odd that people tend to think of “science” as being somehow classified exclusively from “humanities.” Somehow things like literature, history, and philosophy become the study of the human condition while science becomes simply technobabble ruled by equations and esoteric to the point of being completely inaccesible to anyone that hasn’t spent their life chiseling away at their little block of&amp;nbsp;science.&lt;/p&gt;
&lt;p&gt;But in this era of scientific ultra-specialization, its easy to lose sight of the fact that there is nothing more fundamentally human. Science isn’t a set of equations, the latest &lt;span class="caps"&gt;MRI&lt;/span&gt; scanner, deep-space telescope, or vat of chemicals. In its purest essence, science is a way for us to discover what &lt;em&gt;is.&lt;/em&gt; Actually, it’s the &lt;em&gt;only&lt;/em&gt; way for us to explore truth. There is no other tool available to us- which is why science strikes me as the fundamental study of the human condition and our place in the&amp;nbsp;universe.&lt;/p&gt;
&lt;p&gt;In this respect, science is &lt;em&gt;simple.&lt;/em&gt;Its interesting to note that most of the pivotal, truly &lt;em&gt;insightful&lt;/em&gt;revelations that scientists have dreamed up are so basic a child can understand them immediately. Take, for example, Darwin’s theory of evolution. This is (only somewhat) arguably the most important and unifying principle in all of biology (and perhaps the physical sciences as well, see: &lt;a href="http://www.ted.com/talks/lee_cronin_making_matter_come_alive.html"&gt;Lee Cronin&lt;/a&gt;), but it barely requires an ounce more knowledge than what is plainly available to everyone. Okay, well it did take some island hopping and careful observations, but now that the insight is made, its intuitive. Science is a way of looking at the way things are and gaining both incredible power and profound meaning from&amp;nbsp;it.&lt;/p&gt;
&lt;p&gt;Similarly, while Einstein’s theories of relativity may seem stymying and even intimidating, whats truly amazing is that the conclusions they draw can be (and originally were!) arrived at purely on the basis of thought experiments! Think about that. SImply by changing the way that we &lt;em&gt;conceive&lt;/em&gt; of the things we experience, we can create understanding where there was once&amp;nbsp;nothing.&lt;/p&gt;
&lt;p&gt;Do these kinds of insights still happen in science? Sometimes if feels like there’s no way we will make comparable discoveries in our lifetime. Surely we aren’t still missing something as big and far-reaching as evolution or E=mc\^2… Brain science is one of the few fields of inquiry left in which such a paradigm shift can be made. Its my belief that the seemingly intractable problems of consciousness- of what “we” and our subjective experiences even &lt;em&gt;are-&lt;/em&gt;can and will be enlightened by science. Like evolution and relativity, all it requires is the right way of looking at the&amp;nbsp;issue.&lt;/p&gt;
&lt;p&gt;Of course, its entirely neuro-chauvinistic of me to make such a special claim about the brain. After all, we don’t know what we don’t know, and thats why we have&amp;nbsp;science.&lt;/p&gt;</summary><category term="humanities"></category><category term="paradigm"></category><category term="philosophy"></category><category term="science"></category></entry><entry><title>Modern hierarchy of needs</title><link href="http://justmytwospence.github.com/pelican/one-of-my-major-life-goals-is-to-have-my-own-ted.html" rel="alternate"></link><updated>2011-10-03T03:17:00+02:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2011-10-03:one-of-my-major-life-goals-is-to-have-my-own-ted.html</id><summary type="html">&lt;p&gt;[gallery]&lt;/p&gt;
&lt;p&gt;One of my major life goals is to have my own &lt;span class="caps"&gt;TED&lt;/span&gt; talk. In fact, I’m pretty sure if Maslow had been doing his research today, the pinnacle of self-actualization atop his hierarchy of needs would look something like&amp;nbsp;this.&lt;/p&gt;</summary><category term="Hierarchy of needs"></category><category term="ideas worth spreading"></category><category term="Maslow"></category><category term="TED"></category></entry><entry><title>Freesurfer</title><link href="http://justmytwospence.github.com/pelican/freesurfer.html" rel="alternate"></link><updated>2011-10-02T01:51:00+02:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2011-10-02:freesurfer.html</id><summary type="html">&lt;p&gt;Today, two of my housemates and I were sitting around at the living room table when the topic of Foldit came up. &lt;a href="http://fold.it"&gt;Foldit&lt;/a&gt;, if you aren’t aware is a platform that has been developed at the University of Washington jointly between the departments of Computer Science and Biochemistry. It is remarkable in that it solves a major research problem in a completely novel and intriguing&amp;nbsp;way.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://media.tumblr.com/tumblr_lsf1x8N2pZ1r0kwho.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;Protein folding is massively complex. Sure, we can work out the genetic code for a particular protein lickity-split, but the factors that go into determining how that chain of amino acids actually &lt;em&gt;folds&lt;/em&gt; upon itself and forms secondary / tertiary structures are so numerous that its a problem computers can’t solve. Brute force just won’t cut it. What we need is the ability to recognize &lt;em&gt;patterns,&lt;/em&gt;and that is something humans are still &lt;em&gt;much&lt;/em&gt; better at than a computer. (Computers, in their present form, may not &lt;em&gt;ever&lt;/em&gt; be able to match us in this regard- at least in their present form. More on this in a future blog post potentially.) So the solution? Draft huge numbers of humans to do the job, and do it by turning the puzzle problem into a game. The effort has already been hugely successful. You can see the game &lt;span class="caps"&gt;GUI&lt;/span&gt; in the picture&amp;nbsp;above.&lt;/p&gt;
&lt;p&gt;I must have mentioned something about how I wished I could crowd source time-consuming aspects of the processing pipeline in our neuroimaging resource, because Harvey’s (I’ve decided to use first names) response was: “why not?” Harvey is a hard-core entrepreneur, in a way that I never have been but is nonetheless infectious. He will be a multimillionaire one day- there is no doubt in my mind. Before I knew it, he had index cards strewn over the table and was outlining a process chart for how such a system would work for structural analysis of brain &lt;span class="caps"&gt;MRI&lt;/span&gt; data using Freesurfer. So we now have a workflow-comparison of the present pre-processing pipeline, side by side with an idea of how it could theoretically be&amp;nbsp;better.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://media.tumblr.com/tumblr_lsf0tbTpbE1r0kwho.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;Freesurfer takes &lt;span class="caps"&gt;MRI&lt;/span&gt; images that are composed of many brain “slices” (see above) and turns them into surface/volume models that look like&amp;nbsp;this:&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://media.tumblr.com/tumblr_lsf0vmh6rn1r0kwho.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;From there, you can analyze changes in volume and whatnot from individual to individual or from time A to time B. I won’t get into it here, but its really neat&amp;nbsp;stuff.&lt;/p&gt;
&lt;p&gt;Freesurfer is computation-heavy. Multiple steps in the pipeline take 12 or more hours to run. I have 16 servers on my computer in the lab, and when I recruit other processors from around the lab I can get up to 50 or even 100 of these processes running in parallel. After the computer’s algorithms have their crack at the raw data, human quality-checking is necessary because many manual edits typically need to be performed. This can be very time intensive- as I have discovered since beginning work here- with very large data sets. You  need to edit the computer’s output, and then re-run another time-intensive process to actually apply those edits. This is an iterative process until the output is deemed acceptable upon visual&amp;nbsp;inspection. &lt;/p&gt;
&lt;p&gt;Apparently, online platforms for splitting up work that only a human can do already exists online. Check out the Mechanical Turk at mturk.com. What if a system could be designed to crowd-source such steps in the pre-processing pipeline. The necessary cloud-computing infrastructure seems to already exist as well- in the form of Amazon’s elastic compute cloud. It seems- from a scan of the Freesurfer listserv- that Freesurfer has already been run successfully on these servers by other researchers. So the theory is that a cloud-computing web platform could parcel out units of work via mturk (or something similar) and rapidly accomplish steps that otherwise can’t be performed in parallel by one&amp;nbsp;researcher.&lt;/p&gt;
&lt;p&gt;There’s lots of problems with the idea. Foldit has the inhereit benefit of being very puzzle-like, which means there’s a built in game aspect and a sense of discovery. Freesurfer does not have this (its rather monotonous). There could conceivably be a way to gameify it with the right interface, however. There’s also always the possibility of paying for the units of work&amp;nbsp;performed. &lt;/p&gt;
&lt;p&gt;The units of work themselves also pose a problem. A single brain is typically composed of roughly 124 individual “slices”. These would seem to be convenient units to split into, except that one does not edit a freesurfer slice independently of all others. Surrounding slices often inform the anatomy of a slice in question. So maybe hemispheres of the brain could be a useful unit. This, however, is a much larger unit (2 per brain vs. 124 per&amp;nbsp;brain). &lt;/p&gt;
&lt;p&gt;The researcher would still have to do a final &lt;span class="caps"&gt;QC&lt;/span&gt; of the data that the crowd edits, of course. But maybe it could make things more efficient. Even if it wouldn’t work for Freesurfer, the possibility of applying the “Foldit” technique to other fields of study is very intriguing. The key ingredient that is probably missing from this particular instance is a goal-oriented, success-driven component to the&amp;nbsp;activity.&lt;/p&gt;
&lt;p&gt;If you are a scientist reading this post, I’d love to hear your ideas for other tasks found in your research pipeline that could be game-ified and crowdsourced! Leave a&amp;nbsp;comment!&lt;/p&gt;
&lt;p&gt;&lt;span class="caps"&gt;UPDATE&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;Some playing around in Xmind (a free, open source mind-mapping software package), here is a side-by-side comparison of 1) the freesurfer workflow as it stands, 2) the workflow as it would be experienced by a user of this parallel-distribution crowdsourcing- with the web platform as a black box, and 3) a slightly more detailed picture of what would be happening with the&amp;nbsp;data.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://media.tumblr.com/tumblr_lsgyqmXy9c1r0kwho.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;Xmind can be downloaded for free at &lt;a href="http://xmind.net"&gt;xmind.net&lt;/a&gt;&lt;/p&gt;</summary><category term="brain"></category><category term="cloud computing"></category><category term="crowdsourcing"></category><category term="foldit"></category><category term="Freesurfer"></category><category term="gamification"></category><category term="neuroimaging"></category><category term="neuroscience"></category><category term="science"></category></entry><entry><title>Thielfoundation.org</title><link href="http://justmytwospence.github.com/pelican/thielfoundation-org.html" rel="alternate"></link><updated>2011-09-26T03:58:00+02:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2011-09-26:thielfoundation-org.html</id><summary type="html">&lt;p&gt;&lt;a href="http://www.thielfoundation.org/index.php?option=com_content&amp;amp;id=14:the-thiel-fellowship-20-under-20&amp;amp;catid=1&amp;amp;Itemid=16"&gt;Thielfoundation.org&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;About a week ago, my house-mate invited me to has to have been one of the most interesting social events I’ve ever lucked into attending. The founder of Paypal, subsequent multimillion(billion?)aire, and venture capitalist Peter Thiel created a foundation that offers fellowships that amount to anti-college scholarships. Under the program name 20 under 20, he provides brilliant, successful, creative teens with 100,000 dollars over the course of two years to &lt;span class="caps"&gt;NOT&lt;/span&gt; go to Ivy League schools and, instead, become entrepreneurs and and develop their ideas. They must have had some great applications because in their first year, the foundation couldn’t settle on 20 and so there’s something like 23 or 24 in&amp;nbsp;actuality. &lt;/p&gt;
&lt;p&gt;Incredible premise, you might say. And incredible it&amp;nbsp;is.&lt;/p&gt;
&lt;p&gt;My aforementioned house-mate (I haven’t decided if I am going to use real names in this blog yet) has somehow fallen in a few of the fellows, and let me tag along to a social get-together of the foundation. It took place right on the Bay in the Berkeley marina, surrounded by towering sailboats docked on&amp;nbsp;shore.&lt;/p&gt;
&lt;p&gt;We got there fairly late, but during the time that we were there we sure met some interesting characters. My housemate introduced me to a leader in the “seasteading” movement- which is an effort to develop offshore sovereign communities outside of any existing federal jurisdiction in an effort to establish and test alternative, highly libertarian societal structures. Or something like that. In addition, I was brought up to speed on the status of the first “charter cities” being created in Honduras. There is a fantastic &lt;span class="caps"&gt;TED&lt;/span&gt; talk concerning these charter cities that I highly&amp;nbsp;recommend. &lt;/p&gt;
&lt;p&gt;That conversation led us into a discussion with a gentleman about the possibilities such a city would present for medical tourism. Eventually it was discovered that he works for a cryogenics biotech company, and actually used to be the president of Alcor Life Extension Foundation. I’ve been interested in Alcor for a while because its such a controversial and fascinating idea- they will chemically and cryogenically preserve your body (or just your head- if you are on a budget) after death so that if and when we develop technologies to reinstate neural activity, you’ll still be there to do so. This of course raises a whole host of interesting philosophical issues, like what kind of role continuity of neural activity plays in the issue of consciousness or identity, if any. Maybe another blog post on that some day&amp;nbsp;soon.&lt;/p&gt;
&lt;p&gt;Later I met someone working on developing models of brain function in the human neocortex. One of their key premises is that we can create these models in any way we want as long as we successfully mimic the output of the brain, but I happen to disagree on this point. Modeling true intelligence is more than just mimicking output, the &lt;em&gt;way&lt;/em&gt; in which computation is performed is nontrivial. Apparently, another company in the Bay area is taking exactly this approach. Numenta was founded by Jeff Hawkins, the guy who invented Palm Pilot, and is developing cortical learning algorithms that are based on actual biology- much more meaningful in my opinion. I’m in the process of reading everything about Numenta’s work at the moment, and I highly recommend Jeff Hawkins’ &lt;span class="caps"&gt;TED&lt;/span&gt; talk as well if you are at all interested in &lt;span class="caps"&gt;AI&lt;/span&gt;, the brain, or intelligence. There will definitely be another blog post in the near future concerning&amp;nbsp;this.&lt;/p&gt;
&lt;p&gt;Oh, and we almost got abducted by a taco truck. We were both starving and heard the food truck was about to leave, so we ran out to it, but it looked closed up. Several people were climbing in the side door however, so we followed them in hunger-fueled desperation, only to find the door closed behind us. Apparently these other people just needed a ride back to San Fran and were hitchhiking on the truck, but fortunately we managed to bail out before we wound up as unwitting taco-making indentured&amp;nbsp;servants.&lt;/p&gt;</summary><category term="entrepeneurship"></category><category term="silicon valley"></category></entry><entry><title>Nonlinear</title><link href="http://justmytwospence.github.com/pelican/nonlinear.html" rel="alternate"></link><updated>2011-09-25T00:59:00+02:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2011-09-25:nonlinear.html</id><summary type="html">&lt;p&gt;If there is one thing I have learned since graduating from college, it is that life is not linear. I feel that high school, college, and social constructions I have grown up in had programmed me to conceive of life in a very stepwise, linear way. Maybe it’s because you are working so single-mindedly toward holding that diploma in your hand. Or perhaps because you just don’t have much exposure beyond the people who are doing mostly what you are doing. I could be wrong, but I think a lot of college kids have this&amp;nbsp;mentality.&lt;/p&gt;
&lt;p&gt;But it just isn’t. Or at least it doesn’t have to be if you don’t want it to be. You can do absolutely anything you want to in this world, and the arena is &lt;span class="caps"&gt;HUGE&lt;/span&gt;. Like, unimaginably huge. And the Bay Area has to be one of the most incredible places in the world to make this fact hit home. My new home is a mecca for so many different cultural movements. Silicon Valley, entrepeneurs, artists, hippies, &lt;span class="caps"&gt;LGBT&lt;/span&gt; communities, futurists, libertarians, and of course scientists, the last of which I’d like to think I fall&amp;nbsp;into.&lt;/p&gt;
&lt;p&gt;My favorite thing about moving here by far is simply how &lt;em&gt;interesting&lt;/em&gt; everyone I meet is. I mean really really fascinating. Maybe I’ve just been somehow missing how intrinsically awesome the random people I would meet in Tennessee and Houston were. But here, in a single night you can meet people who work for Google and Facebook, people who hunt planets for &lt;span class="caps"&gt;NASA&lt;/span&gt;, people crafting all manner of crazy or thoughtful or brilliant startups, people who have attended universities all over the country and the world… I could go on and&amp;nbsp;on. &lt;/p&gt;
&lt;p&gt;That’s one thing I hope to do with this blog: highlight the amazing people and projects that I come across. These people are not living linear lives. And just being in this crazy, fast paced, marvelously jumbled community is creating a paradigm shift in the way that I see the world. Its tough to explain, but I guess I’m realizing how things are out there for you to take and affect and become a part of- &lt;em&gt;big&lt;/em&gt; things- and all you have to do is try. The rough plan for this blog is to make it about &lt;strong&gt;ideas&lt;/strong&gt;, &lt;strong&gt;adventures&lt;/strong&gt;, and &lt;strong&gt;discoveries&lt;/strong&gt;. No promises for how it will turn out developing&amp;nbsp;though.&lt;/p&gt;
&lt;p&gt;Here’s to being&amp;nbsp;nonlinear!&lt;/p&gt;</summary></entry></feed>