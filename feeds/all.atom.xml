<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>justmytwospence</title><link href="http://justmytwospence.github.com/pelican/" rel="alternate"></link><link href="http://justmytwospence.github.com/pelican/feeds/all.atom.xml" rel="self"></link><id>http://justmytwospence.github.com/pelican/</id><updated>2014-03-22T18:38:32+01:00</updated><entry><title>Stratified sampling in R</title><link href="http://justmytwospence.github.com/pelican/stratified-sampling-in-r.html" rel="alternate"></link><updated>2014-03-22T18:38:32+01:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2014-03-22:stratified-sampling-in-r.html</id><summary type="html">&lt;html&gt;&lt;body&gt;&lt;p&gt;I was surprised to find that R doesn’t have a base function for stratified random sampling. There’s not even a well known package I could find that does this in a straight forward way. So heres my own.&lt;/p&gt;
&lt;p&gt;It is essentially a wrapper for a ddply call that samples each subset and then combines them. If the size argument is less than 1, it will be interpreted as the percentage of each stratification subset that should be sampled. If the size argument is greater than 1, it will be interpreted as the number of observations to sample from each stratification subset. &lt;/p&gt;
&lt;p&gt;Note that in the first case, a different number of observations will be taken from each subset depending on their total number of observations. In the second case however, an equal number of observations will be sampled from each subset, regardless of their total number of observations.&lt;/p&gt;
&lt;p&gt;The .by argument is formulated the same way it is for any other ddply call.&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;script src="https://gist.github.com/justmytwospence/7937389.js"&gt;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt;</summary></entry><entry><title>What's a Mooc?</title><link href="http://justmytwospence.github.com/pelican/whats-a-mooc.html" rel="alternate"></link><updated>2014-03-14T14:13:00+01:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2014-03-14:whats-a-mooc.html</id><summary type="html">&lt;html&gt;&lt;body&gt;&lt;p&gt;Turns out that Robert de Niro and friends are facing a problem very  similar to the one facing Coursera and friends…&lt;/p&gt;
&lt;div align="center" class="youtube"&gt;&lt;iframe frameborder="0" height="315" src="https://www.youtube.com/embed/8vw8t4O9JQM" width="420"&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;p&gt;From the 1973 movie &lt;a class="reference external" href="http://www.imdb.com/title/tt0070379/?ref_=fn_al_tt_1"&gt;Mean Streets&lt;/a&gt;. Apparently Scorsese predicted the education revolution wayy ahead of his time and had a pretty good grasp on the biggest challenges that MOOCs would need to overcome.&lt;/p&gt;
&lt;/body&gt;&lt;/html&gt;</summary><category term="Coursera"></category><category term="education"></category><category term="MOOC"></category></entry><entry><title>writeLaTeX</title><link href="http://justmytwospence.github.com/pelican/writelatex.html" rel="alternate"></link><updated>2014-01-25T18:42:00+01:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2014-01-25:writelatex.html</id><summary type="html">&lt;html&gt;&lt;body&gt;&lt;p&gt;If you use \(\LaTeX\) and haven’t yet heard of
\(write\LaTeX\), do yourself a favor and check it out. On one level
its a really great version of Google Docs for documents that are
properly typeset, which is incredibly useful because a huge swathe of
the documents created with \(\LaTeX\) are inherently collaborative in
nature. Its other fantastic feature is that your \(\LaTeX\) markup is
automatically rendered in real-time (or close to it, at least, there’s a
few seconds of lag depending on the length of the document). This made
writing my first \(\LaTeX\) intensive document a great experience,
because I could experiment liberally with equations and figure
placement. There’s literally zero barrier to entry because its
completely web based; you don’t need to install a thing and templates
are available to get you jump-started. Right now other engines like
XeLaTeX aren’t supported, but I believe they are in the works.&lt;/p&gt;
&lt;p&gt;So every excuse you ever had to not learn \(\LaTeX\) has been
obliterated. Give [\(write\LaTeX\)][] a try, or be passive aggressive
and send it to that collaborator that always sends you everything in a
poorly formatted Word document. I myself will be experimenting with
using \(\LaTeX\) to take math-heavy notes in real-time, which sounds
crazy but the live rendering makes the attempt feasible.&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;</summary><category term="latex"></category><category term="tex"></category><category term="typesetting"></category><category term="writelatex"></category></entry><entry><title>Titanic: Getting Started With R</title><link href="http://justmytwospence.github.com/pelican/titanic-getting-started-with-r.html" rel="alternate"></link><updated>2014-01-11T22:05:00+01:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2014-01-11:titanic-getting-started-with-r.html</id><summary type="html">&lt;html&gt;&lt;body&gt;&lt;p&gt;My friend and classmate &lt;a href="http://trevorstephens.com"&gt;Trevor Stephens&lt;/a&gt; has created some &lt;a href="http://trevorstephens.com/post/72916401642/titanic-getting-started-with-r"&gt;pretty stellar R tutorials&lt;/a&gt; that will take you to about halfway up the leaderboard of Kaggle’s &lt;a href="http://www.kaggle.com/c/titanic-gettingStarted"&gt;Titanic: Machine Learning from Disaster&lt;/a&gt; competition. While the competition has a &lt;a href="http://www.kaggle.com/c/titanic-gettingStarted/details/getting-started-with-python"&gt;Python tutorial&lt;/a&gt; and even a beginner’s &lt;a href="http://www.kaggle.com/c/titanic-gettingStarted/details/getting-started-with-excel"&gt;Excel tutorial&lt;/a&gt;, any R equivalent had been suspiciously lacking. This is the competition that served as our first foray into machine learning, so kudos to Trevor for giving back to the community!&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;</summary><category term="kaggle"></category><category term="machine learning"></category><category term="R"></category></entry><entry><title>Live mapping</title><link href="http://justmytwospence.github.com/pelican/live-mapping.html" rel="alternate"></link><updated>2014-01-08T08:50:00+01:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2014-01-08:live-mapping.html</id><summary type="html">&lt;html&gt;&lt;body&gt;&lt;p&gt;I’ve been wanting to do some more mapping stuff since my first encounter with Leaflet a month or two ago while I was working on a project for &lt;a href="http://auto-grid.com"&gt;AutoGrid&lt;/a&gt;. I had my eye on CartoDB’s time series library, &lt;a href="https://github.com/cartodb/torque"&gt;Torque&lt;/a&gt;, because I had really wanted to do some time-series visualization, but time constraints and privacy issues with uploading data to CartoDB’s servers prevented me from really exploring. Since I had a few days of free time over winter break, I played around with it a bit and came up with this: &lt;a href="http://www.spencerboucher.com/map"&gt;spencerboucher.com/map&lt;/a&gt;. How’d I do it?
&lt;br/&gt;
First I needed some geographic data, so I turned to a source of data I’ve been collected for almost a year - my own location. &lt;a href="http://openpaths.cc"&gt;OpenPaths&lt;/a&gt; is a mobile app that records your location at regular time intervals. I opted for every 30 minutes at first, then upped it to every 15 minutes when I discovered that the effect on battery life wasn’t nearly as bad as I expected it to be. OpenPaths is a project of &lt;a href="http://nytlabs.com/"&gt;the R&amp;amp;D department at The New York Times&lt;/a&gt; and they &lt;a href="https://openpaths.cc/FAQ"&gt;claim&lt;/a&gt; that you are the only one with access to the collected data. Interestingly, you can grant various &lt;a href="https://openpaths.cc/projects"&gt;research programs&lt;/a&gt; access to your data at your own discretion. Your data is conveniently downloadable as a csv, json, or kml file, so I easily pulled my dataset of \~3,000 time points since December 2012. Unfortunately, I made the switch from iPhone to Android around April (well, that part is fortunate), and forgot to re-download the app, so I only really have data from the around the first three months and last two months of 2013.
&lt;br/&gt;
Turns out, making impressive maps with CartoDB is almost embarrassingly easy. Their &lt;span class="caps"&gt;GUI&lt;/span&gt; is pretty intuitive and running queries on their postgreSQL database is simple. Even time series stuff built on the Torque backend is really just point and click. I decided that the best way to visualize this data was with an aggregated hexbin heatmap of all my past locations, overlaid with a point-by-point replay with a time-slider. From there, it was just a one-line &lt;span class="caps"&gt;API&lt;/span&gt; call to host the map on my website (line 30 highlighted below), which is significantly easier than the legwork that went into crafting a Leaflet map “manually.”&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nt"&gt;&amp;lt;html&amp;gt;&lt;/span&gt;

&lt;span class="nt"&gt;&amp;lt;head&amp;gt;&lt;/span&gt;

  &lt;span class="nt"&gt;&amp;lt;meta&lt;/span&gt; &lt;span class="na"&gt;name=&lt;/span&gt;&lt;span class="s"&gt;"viewport"&lt;/span&gt; &lt;span class="na"&gt;content=&lt;/span&gt;&lt;span class="s"&gt;"initial-scale=1.0, user-scalable=no"&lt;/span&gt; &lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;

  &lt;span class="nt"&gt;&amp;lt;title&amp;gt;&lt;/span&gt;Location | Spencer&lt;span class="nt"&gt;&amp;lt;/title&amp;gt;&lt;/span&gt;

  &lt;span class="nt"&gt;&amp;lt;link&lt;/span&gt; &lt;span class="na"&gt;rel=&lt;/span&gt;&lt;span class="s"&gt;"shortcut icon"&lt;/span&gt; &lt;span class="na"&gt;href=&lt;/span&gt;&lt;span class="s"&gt;"http://spencerboucher.com/map/favicon.png"&lt;/span&gt; &lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;link&lt;/span&gt; &lt;span class="na"&gt;rel=&lt;/span&gt;&lt;span class="s"&gt;"stylesheet"&lt;/span&gt; &lt;span class="na"&gt;href=&lt;/span&gt;&lt;span class="s"&gt;"http://libs.cartocdn.com/cartodb.js/v3/themes/css/cartodb.css"&lt;/span&gt; &lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
  &lt;span class="c"&gt;&amp;lt;!--[if lte IE 8]&amp;gt;&lt;/span&gt;
&lt;span class="c"&gt;    &amp;lt;link rel="stylesheet" href="http://libs.cartocdn.com/cartodb.js/v3/themes/css/cartodb.ie.css" /&amp;gt;&lt;/span&gt;
&lt;span class="c"&gt;  &amp;lt;![endif]--&amp;gt;&lt;/span&gt;

  &lt;span class="nt"&gt;&amp;lt;style &lt;/span&gt;&lt;span class="na"&gt;type=&lt;/span&gt;&lt;span class="s"&gt;"text/css"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
      &lt;span class="nt"&gt;html&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;body&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nf"&gt;#map&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
          &lt;span class="k"&gt;margin&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
          &lt;span class="k"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
          &lt;span class="k"&gt;width&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="m"&gt;100&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
          &lt;span class="k"&gt;height&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="m"&gt;100&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
          &lt;span class="k"&gt;background&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;black&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
      &lt;span class="nf"&gt;#cartodb-gmaps-attribution&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="k"&gt;visibility&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="k"&gt;hidden&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;/style&amp;gt;&lt;/span&gt;

  &lt;span class="nt"&gt;&amp;lt;script &lt;/span&gt;&lt;span class="na"&gt;src=&lt;/span&gt;&lt;span class="s"&gt;"http://maps.google.com/maps/api/js?v=3.2&amp;amp;sensor=false"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&amp;lt;/script&amp;gt;&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;script &lt;/span&gt;&lt;span class="na"&gt;src=&lt;/span&gt;&lt;span class="s"&gt;"http://libs.cartocdn.com/cartodb.js/v3/cartodb.js"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&amp;lt;/script&amp;gt;&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;script&amp;gt;&lt;/span&gt;
    &lt;span class="kd"&gt;function&lt;/span&gt; &lt;span class="nx"&gt;init&lt;/span&gt;&lt;span class="p"&gt;(){&lt;/span&gt;
      &lt;span class="nx"&gt;cartodb&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;createVis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'map'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'http://justmytwospence.cartodb.com/api/v2/viz/e8fd87d0-78b3-11e3-a9e9-e7941b6e2df0/viz.json'&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;/script&amp;gt;&lt;/span&gt;

&lt;span class="nt"&gt;&amp;lt;/head&amp;gt;&lt;/span&gt;

&lt;span class="nt"&gt;&amp;lt;body&lt;/span&gt; &lt;span class="na"&gt;onload=&lt;/span&gt;&lt;span class="s"&gt;"init()"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;div&lt;/span&gt; &lt;span class="na"&gt;id=&lt;/span&gt;&lt;span class="s"&gt;'map'&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&amp;lt;/div&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;/body&amp;gt;&lt;/span&gt;

&lt;span class="nt"&gt;&amp;lt;/html&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This is pretty awesome, but in light of how easy it all was, I was almost disappointed. Can we take it one step further? Let’s put on our &lt;a href="http://quantifiedself.com/about/"&gt;Quantified Self&lt;/a&gt; hats and set about to make this map &lt;em&gt;live&lt;/em&gt;. There’s three components to making this happen, so we’ll step through them one at a time. First we need to access the most recent data from OpenPaths (there’s an &lt;span class="caps"&gt;API&lt;/span&gt; for that!), and then we need to insert that data into CartoDB’s database (guess what, there’s an &lt;span class="caps"&gt;API&lt;/span&gt; for that too). Last but not least, we need to schedule that data transplant to occur on a regular basis. The Unix utility &lt;code&gt;cron&lt;/code&gt; is the canonical tool for this type of thing, so this seemed like a good time to learn how to use it.

Python has a reputation for being a great “glue” language, so that’s what we’ll use to build this script.
&lt;br/&gt;
Programmatically accessing your data from OpenPaths is super simple. This piece of our script is pulled more or less verbatim from &lt;a href="https://openpaths.cc/api"&gt;the OpenPaths &lt;span class="caps"&gt;API&lt;/span&gt; documentation&lt;/a&gt;. Line 21 (highlighted below) is key - this is where we specify which data you want to pull for injection into the CartoDB database. Here we will grab the last 24 hours of data (\~96 readings, if you’re collecting every 15 minutes like me), getting the results in a nice  &lt;span class="caps"&gt;JSON&lt;/span&gt;-formatted variable named &lt;code&gt;data&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;oauth2&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nn"&gt;time&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nn"&gt;urllib&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nn"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nn"&gt;json&lt;/span&gt;

&lt;span class="n"&gt;ACCESS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;'redacted'&lt;/span&gt;
&lt;span class="n"&gt;SECRET&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;'redacted'&lt;/span&gt;
&lt;span class="n"&gt;URL&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;'https://openpaths.cc/api/1'&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;build_auth_header&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;method&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;params&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="s"&gt;'oauth_version'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;"1.0"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s"&gt;'oauth_nonce'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;oauth2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;generate_nonce&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
        &lt;span class="s"&gt;'oauth_timestamp'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()),&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="n"&gt;consumer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;oauth2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Consumer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ACCESS&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;secret&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;SECRET&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;'oauth_consumer_key'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;consumer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt; 
    &lt;span class="n"&gt;request&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;oauth2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Request&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;method&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;method&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;parameters&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;signature_method&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;oauth2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SignatureMethod_HMAC_SHA1&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sign_request&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;signature_method&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;consumer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_header&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;now&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;params&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;'start_time'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;now&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;24&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="mi"&gt;60&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="mi"&gt;60&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;'end_time'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;now&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="c"&gt;# get the last 24 hours&lt;/span&gt;
&lt;span class="n"&gt;query&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;"&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt;?&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt;"&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;URL&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;urllib&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;urlencode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="c"&gt;#print(query)&lt;/span&gt;
&lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;request&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Request&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;query&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;headers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;build_auth_header&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;URL&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;'GET'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;connection&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;urlopen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loads&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;''&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;connection&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;readlines&lt;/span&gt;&lt;span class="p"&gt;()))&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dumps&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;indent&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="n"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;HTTPError&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now we need to get our new &lt;code&gt;data&lt;/code&gt; variable into CartoDB’s postgreSQL server. &lt;a href="http://developers.cartodb.com/documentation/sql-api.html"&gt;CartoDB’s &lt;span class="caps"&gt;SQL&lt;/span&gt; &lt;span class="caps"&gt;API&lt;/span&gt; documentation&lt;/a&gt; makes this possible, and there’s even a &lt;a href="https://github.com/vizzuality/cartodb-python"&gt;python module&lt;/a&gt; that wraps OAuth2 to simplify things. Although its still in the early stages of development, this module works fine for our current purposes; all we have to do is send it a string that holds the &lt;span class="caps"&gt;SQL&lt;/span&gt; query we want to run. So now we’ll just write a for-loop that successively builds an &lt;code&gt;INSERT&lt;/code&gt; query for each element in &lt;code&gt;data&lt;/code&gt; (lines 18-20 highlighted below).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;cartodb&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;CartoDBException&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;CartoDBAPIKey&lt;/span&gt;

&lt;span class="n"&gt;user&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="s"&gt;'spencer.g.boucher@gmail.com'&lt;/span&gt;
&lt;span class="n"&gt;password&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="s"&gt;'redacted'&lt;/span&gt;
&lt;span class="n"&gt;cartodb_domain&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;'justmytwospence'&lt;/span&gt;
&lt;span class="n"&gt;API_KEY&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;'redacted'&lt;/span&gt;
&lt;span class="n"&gt;cl&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;CartoDBAPIKey&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;API_KEY&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cartodb_domain&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;reading&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;alt&lt;/span&gt;     &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;reading&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;'alt'&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;device&lt;/span&gt;  &lt;span class="o"&gt;=&lt;/span&gt;     &lt;span class="n"&gt;reading&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;'device'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;lat&lt;/span&gt;     &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;reading&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;'lat'&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;lon&lt;/span&gt;     &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;reading&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;'lon'&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;os&lt;/span&gt;      &lt;span class="o"&gt;=&lt;/span&gt;     &lt;span class="n"&gt;reading&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;'os'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;t&lt;/span&gt;       &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;reading&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;'t'&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;version&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;     &lt;span class="n"&gt;reading&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;'version'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;query_string&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;"INSERT INTO openpaths_justmytwospence (alt, date, device, lat,  lon, os, version, the_geom) "&lt;/span&gt;
                       &lt;span class="s"&gt;"VALUES ({0}, abstime({1}), '{2}', {3}, {4}, '{5}', '{6}', ST_ SetSRID(ST_Point({4}, {3}), 4326))"&lt;/span&gt;  
                      &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;alt&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;device&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lat&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lon&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;version&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;cl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sql&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;query_string&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="n"&gt;CartoDBException&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"some error ocurred"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;A few notes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It would certainly be faster to insert all of the new data into the
    database using a single &lt;code&gt;INSERT&lt;/code&gt; statement, but that would require
    some more tedious text parsing and execution speed isn’t
    particularly important to us. As it stands, it takes about six
    seconds to post a day’s worth of data.&lt;/li&gt;
&lt;li&gt;One posgreSQL “gotcha” had me hung up for quite some time: single
    quotes parse fine but double quotes do not.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ST_SetSRID&lt;/code&gt; is a &lt;a href="http://postgis.org/docs/ST_SetSRID.html"&gt;PostGIS command&lt;/a&gt; that converts a lon/lat pair
    (in that order - another “gotcha”) to the necessary geometry object.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;Last but not least, we need this script to run automatically. Because we’ve written the script to transplant 24 hours of data, we’ll need to run it once a day in order to capture all of the data that’s being generated. I tried to set up my web host, &lt;a href="https://laughingsquid.us/"&gt;LaughingSquid&lt;/a&gt;, to do this, but unfortunately they don’t grant shell access so we can’t install all those fancy python modules that we’ve already used. Its totally possible to rewrite the script to use only modules from the &lt;a href="http://docs.python.org/2/library/"&gt;Python Standard Library&lt;/a&gt;, but this would turn a simple task into a tedious one. Manually implementing OAuth in particular would be a total pain in the rear, and classes are just about to resume after all, so a different solution is in order. Let’s spin up a &lt;a href="http://aws.amazon.com/"&gt;“micro” &lt;span class="caps"&gt;EC2&lt;/span&gt; instance&lt;/a&gt; instead. This gives us free reign to install whatever we need for the low low cost of ¢.02 per hour. This does start to add up, but our Master’s program gives us some pretty substantial Amazon Web Services credit that goes mostly unused, so we aren’t too upset :). &lt;span class="caps"&gt;UPDATE&lt;/span&gt;: A new post provides details about how to schedule Amazon &lt;span class="caps"&gt;EC2&lt;/span&gt; instances - &lt;a href="http://www.spencerboucher.com/ec2-apis/"&gt;http://www.spencerboucher.com/ec2-apis/&lt;/a&gt;.
&lt;br/&gt;
After &lt;code&gt;pip install&lt;/code&gt;ing everything we need and &lt;code&gt;scp&lt;/code&gt;ing our python script (let’s call it update.py) into the home directory of our remote server, all we need to do is set up a crontab with the &lt;code&gt;crontab -e&lt;/code&gt; command and add the following line:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;@daily /usr/bin/python ~/update.py
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;code&gt;@daily&lt;/code&gt; is actually a shortcut for &lt;code&gt;* * * * *&lt;/code&gt;, where each asterix is a
placeholder for the (respectively) minute, hour, day of month, month,
and day of week that the script should executed. This shortcut defaults
to midnight every day, which is really as good as anything for our
purposes.
&lt;br/&gt;
Voilà! Now we can step back and relax, knowing that we don’t have to do a single thing and our map will continue to show the most up-to-date data available.
&lt;br/&gt;
A few final notes: 
-   We might reasonably want to lag our script by a week or so, for security/privacy reasons.
-   As far as I can tell, the location readings are recorded in a &lt;a href="http://en.wikipedia.org/wiki/Unix_time"&gt;&lt;span class="caps"&gt;POSIX&lt;/span&gt; time&lt;/a&gt; and have not been adjusted by time zone, so they are still in the &lt;a href="http://en.wikipedia.org/wiki/Coordinated_Universal_Time"&gt;&lt;span class="caps"&gt;UTC&lt;/span&gt;&lt;/a&gt; time zone. This means that they are 8 hours off from the actual time in California, where I usually am. This doesn’t bother me too much at the moment because the visualization is still relatively low resolution in the time domain anyways. At some point I might implement the relevant transformation, but this will raise its own issues because I won’t &lt;em&gt;always&lt;/em&gt; be in California, not to mention all that Daylight Savings nonsense.
-   [Click here for an addendum to this post that will take you through how to schedule the &lt;span class="caps"&gt;EC2&lt;/span&gt; instance and avoid having it run 24/7][]&lt;/p&gt;
&lt;p&gt;[Click here for an addendum to this post that will take you through
  how to schedule the &lt;span class="caps"&gt;EC2&lt;/span&gt; instance and avoid having it run 24/7]: http://www.spencerboucher.com/ec2-apis/
    “Scheduling tasks in the cloud with &lt;span class="caps"&gt;EC2&lt;/span&gt; APIs”&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;</summary><category term="api"></category><category term="aws"></category><category term="cartoDB"></category><category term="cartography"></category><category term="cron"></category><category term="ec2"></category><category term="map"></category><category term="quantifiedSelf"></category></entry><entry><title>Luke attempts a novel analysis in SAS</title><link href="http://justmytwospence.github.com/pelican/luke-skywalker-attempts-a-novel-analysis-in-sas.html" rel="alternate"></link><updated>2014-01-06T22:17:00+01:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2014-01-06:luke-skywalker-attempts-a-novel-analysis-in-sas.html</id><summary type="html"></summary><category term="SAS"></category><category term="R"></category></entry><entry><title>Luke Skywalker on SAS</title><link href="http://justmytwospence.github.com/pelican/luke-skywalker-on-sas.html" rel="alternate"></link><updated>2013-12-09T00:24:00+01:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2013-12-09:luke-skywalker-on-sas.html</id><summary type="html"></summary><category term="SAS"></category><category term="R"></category></entry><entry><title>Kaggle(esque)</title><link href="http://justmytwospence.github.com/pelican/kaggle-esque.html" rel="alternate"></link><updated>2013-12-07T06:38:00+01:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2013-12-07:kaggle-esque.html</id><summary type="html">&lt;html&gt;&lt;body&gt;&lt;p&gt;Our program hosted its own Kaggle-style competition this quarter, featuring a “mystery” dataset with a binary target variable. I was impressed by the reveal.js javascript library, so I put together our final slides using it, both because its pretty, and as a way to get some more practice with &lt;span class="caps"&gt;HTML&lt;/span&gt;, &lt;span class="caps"&gt;CSS&lt;/span&gt;, and javascript. On top of that, I had to expand my knowledge of Git in order to publish it on their GitHub Pages platform, so wins all around. Check out the work of Team LoanShark here:&lt;/p&gt;
&lt;iframe height="500" src="http://justmytwospence.github.io/LoanSharks/slides/#/" width="100%"&gt;
Your browser doesn’t support iframes. Do yourself a favor and go
download a *real* browser
&lt;/iframe&gt;&lt;/body&gt;&lt;/html&gt;</summary><category term="javascript"></category><category term="reveal.js"></category></entry><entry><title>Map-time at Stamen</title><link href="http://justmytwospence.github.com/pelican/map-time-at-stamen.html" rel="alternate"></link><updated>2013-12-01T02:37:00+01:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2013-12-01:map-time-at-stamen.html</id><summary type="html">&lt;html&gt;&lt;body&gt;&lt;p&gt;Last week, a classmate and I took a break from coursework to attend one of the many great Meetup events that San Francisco has to offer for data science practitioners. I’ve been pushing myself to attend at least one data-centric Meetup every week, because these events are one of the most amazing parts about going to school in the same place where so many of the biggest names work. To be honest, I believe that becoming a presence in the data science scene and meeting the movers and shakers is equally if not more important than coursework.&lt;/p&gt;
&lt;p&gt;I actually attended 3 meetups last week, one about D3.js at Trulia &lt;span class="caps"&gt;HQ&lt;/span&gt;, one about &lt;span class="caps"&gt;GIS&lt;/span&gt; technologies and the Code for America &lt;span class="caps"&gt;HQ&lt;/span&gt;, and one about mapping at Stamen &lt;span class="caps"&gt;HQ&lt;/span&gt;. I picked all three because they are relevant to a geospatial data visualization that I am working on for my practicum at AutoGrid, but the last one is what I’m going to talk a bit about, because it was the most hands-on.&lt;/p&gt;
&lt;p&gt;The workshop took place at Stamen Design’s headquarters in the Mission and was led by Eric Theise; you can see his beautiful/informative slides (created using &lt;a href="http://lab.hakim.se/reveal-js/#/"&gt;reveal.js&lt;/a&gt;) here:   &lt;a href="http://erictheise.com/maptime_platform_slides/#/"&gt;&lt;/a&gt;&lt;a href="http://erictheise.com/maptime_platform_slides/#/"&gt;http://erictheise.com/maptime_platform_slides/#/&lt;/a&gt;      Some useful Q&amp;amp;A happened on the Meetup event page as well:   &lt;a href="http://www.meetup.com/Maptime-SF/events/147110652/"&gt;&lt;/a&gt;&lt;a href="http://www.meetup.com/Maptime-SF/events/147110652/"&gt;http://www.meetup.com/Maptime-&lt;span class="caps"&gt;SF&lt;/span&gt;/events/147110652/&lt;/a&gt; &lt;/p&gt;
&lt;p&gt;This was actually a two-part workshop, but it was relatively painless to follow the instructions and get up to speed for the part &lt;span class="caps"&gt;II&lt;/span&gt;, so you should really give it a shot even now if it looks interesting.&lt;/p&gt;
&lt;p&gt;First we got postgres up and running on our machines. I have local installations of MySQL, MongoDB, Hadoop and Hive up and running thanks to our course in Distributed Databases, but our class didn’t have time to get to postgres within a single credit hour. This, despite the fact that our professor admits to postgres being the best database to use if you have anything to say about it.&lt;/p&gt;
&lt;p&gt;Next, we populated our database with some data from OpenStreetMap. Mike Migurski extracts data from &lt;span class="caps"&gt;OSM&lt;/span&gt; for major metropolitan areas on a semi-regular basis, so we used the San Francisco data &lt;a href="http://metro.teczno.com/#san-francisco"&gt;available on his web site&lt;/a&gt; via &lt;a href="http://wiki.openstreetmap.org/wiki/Osm2pgsql"&gt;osm2pgsql&lt;/a&gt;, a command-line utility that loads OpenStreetMap data into PostgreSQL databases.&lt;/p&gt;
&lt;p&gt;Then we used &lt;a href="https://www.mapbox.com/tilemill/"&gt;TileMill&lt;/a&gt;, MapBox’s desktop application, to visualize our newborn database. We discovered how remarkably easy it can be to create vector layers for data contained in such a postGIS database using the same old &lt;span class="caps"&gt;SQL&lt;/span&gt; and &lt;span class="caps"&gt;CSS&lt;/span&gt; syntax you already know and love. Eric introduced us to some sensible pre-baked &lt;a href="https://github.com/gravitystorm/openstreetmap-carto"&gt;CartoCSS boilerplate&lt;/a&gt; courtesy of Andy Allen.&lt;/p&gt;
&lt;p&gt;Lastly, we used a nifty feature of TileMill to actually bake our own map tiles and serve them up for use in our own maps. Note that if you want to do this, you’ll need the &lt;a href="https://github.com/mapbox/mbutil"&gt;mbutil command-line utility&lt;/a&gt;, not currently mentioned in the slide deck.&lt;/p&gt;
&lt;p&gt;Not too shabby for 2 hours on a Wednesday night. Many thanks to the guys at Stamen for hosting, especially Eric for all his work on the slides. Not to mention the many other brilliant people who have made the tools and resources that allow something this involved and grandiose to be done on a laptop by someone who is still learning the ropes. Hands-on workshops like this are one of the best ways to learn these technologies. Case in point, I may not have ever stumbled across Mike or Andy’s resources had I not been learning directly from people who are intimately familiar with the practical ins and outs of digital cartography.&lt;/p&gt;
&lt;p&gt;Digital mapping is rapidly capturing my interest because of the beautifully functional things one can do with it, and it seems like an amazing time to be learning it, because the ecosystem is beginning to really flourish. Looking forward to more events!&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;</summary><category term="cartography"></category><category term="maps"></category></entry><entry><title>StepLively update</title><link href="http://justmytwospence.github.com/pelican/steplively-update.html" rel="alternate"></link><updated>2013-11-03T21:59:00+01:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2013-11-03:steplively-update.html</id><summary type="html">&lt;html&gt;&lt;body&gt;&lt;p&gt;This week I got an email from RStudio letting me know that after a week or two of waiting, I’ve been assigned &lt;span class="caps"&gt;2GB&lt;/span&gt; of space on their servers for hosting Shiny apps. So now you can click on the above link to see the live version of my stepwise regression app that I posted last week. In celebration, I’ve added a few extras to the app, including the ability to upload your own data set, although its not a particularly robust feature yet.&lt;/p&gt;
&lt;p&gt;Update: I’ve recently moved to Rstudio’s next-gen hosting platform: shinyapps.io. This was necessary because I was having issues installing low-level packages like Rcpp onto their Spark server. This new platform is much more flexible in this regard. I’ve updated links accordingly.&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;</summary><category term="R"></category><category term="Shiny"></category><category term="stepwise"></category></entry><entry><title>Switching R versions on-the-fly</title><link href="http://justmytwospence.github.com/pelican/switching-r-versions-on-the-fly.html" rel="alternate"></link><updated>2013-10-22T22:01:00+02:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2013-10-22:switching-r-versions-on-the-fly.html</id><summary type="html">&lt;html&gt;&lt;body&gt;&lt;p&gt;If you need to switch back to an older version of R to use a particular package, it doesn’t get easier than downloading the &lt;a href="http://r.research.att.com/"&gt;RSwitcher utility from &lt;span class="caps"&gt;AT&lt;/span&gt;&amp;amp;T&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I use homebrew to keep my main installation up-to-date, and then switching back to 2.7 when I need a certain package is as easy as one click.&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;</summary><category term="R"></category></entry><entry><title>Holo color palette</title><link href="http://justmytwospence.github.com/pelican/holo-color-palette.html" rel="alternate"></link><updated>2013-08-20T06:19:00+02:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2013-08-20:holo-color-palette.html</id><summary type="html">&lt;html&gt;&lt;body&gt;&lt;p&gt;Despite being slightly colorblind, I’m one of those
people who is bizarrely anal-retentive when it comes to color-schemes in
the software that I use. I use custom &lt;span class="caps"&gt;CSS&lt;/span&gt; extensions in Chrome to make
the color schemes of websites like Wikipedia, Youtube, etc a bit more
pleasing. I did some digging in the accessibility preference pane of
Adobe Reader to make the default document background a nice book-like
sepia tone which makes reading PDFs online a much less straining
endeavor (incidentally - Google Play Books &lt;em&gt;only&lt;/em&gt; has a white background
which is why I greatly prefer the Amazon Kindle web app). I’ve spent
wayy too long (as I think many geeks do), customizing my terminal and
custom android &lt;span class="caps"&gt;ROM&lt;/span&gt; themes. I think you get the picture.&lt;/p&gt;
&lt;p&gt;Anyways, I had been using the Solarized palette for a lot of things
because it seems like its choices are a bit less arbitrary and has some
science behind it (although I haven’t done any research into how
legitimate that science is). Its a bit limiting, however, and recently
I’ve been attracted to the Holo color palette that &lt;span class="caps"&gt;ICS&lt;/span&gt; compliant Android
apps use. I couldn’t find a pre-compiled Holo palette in .clr format for
use in the Mac &lt;span class="caps"&gt;OSX&lt;/span&gt; Color Picker utility, so I made a simple, bare-bones
one. First I had to download the &lt;span class="caps"&gt;HEX&lt;/span&gt; plugin from &lt;a href="http://wafflesoftware.net/hexpicker/"&gt;wafflesoftware.net&lt;/a&gt;
which for some strange reason is not a functionality that Apple thought
worthwhile to put into a color picker (???). &lt;a href="http://db.tt/xU7lyIBh"&gt;You can download my .clr
palette right here&lt;/a&gt;. Maybe I can save the next anal-retentive googler
a few minutes.&lt;/p&gt;
&lt;p&gt;&lt;span class="caps"&gt;PS&lt;/span&gt;. While I am talking about color - if you haven’t heard of &lt;a href="http://justgetflux.com/"&gt;fl.ux&lt;/a&gt;,
check it out. It is a magical little utility that warms the color of
your screen automatically after sunset and can &lt;em&gt;really&lt;/em&gt; save your eyes
and make getting to sleep a little bit easier if you are working in
front of your screen late at night.&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;</summary><category term="color"></category><category term="holo"></category><category term="solarized"></category></entry><entry><title>Twitter Reaction to Events Often at Odds with Overall Public Opinion</title><link href="http://justmytwospence.github.com/pelican/twitter-reaction-to-events-often-at-odds-with-overall.html" rel="alternate"></link><updated>2013-08-06T00:09:00+02:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2013-08-06:twitter-reaction-to-events-often-at-odds-with-overall.html</id><summary type="html">&lt;html&gt;&lt;body&gt;&lt;p&gt;[Twitter Reaction to Events Often at Odds with Overall Public Opinion][]&lt;/p&gt;
&lt;p&gt;This is a long-standing beef that I have always had with any Twitter-sentiment analysis. A huge chunk of people tweeting are just whiny adolescents who wouldn’t even be polled if we were to design a huge study. I haven’t heard of any twitter-mining tools or packages that allow you to filter the Twitterers that you are pulling your random sample of tweets from. That would certainly be worthwhile and would make a lot of people care a lot more about Twitter sentiment analyses.&lt;/p&gt;
&lt;p&gt;[Twitter Reaction to Events Often at Odds with Overall Public
  Opinion]: http://www.pewresearch.org/2013/03/04/twitter-reaction-to-events-often-at-odds-with-overall-public-opinion/&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;</summary></entry><entry><title>On being approximate</title><link href="http://justmytwospence.github.com/pelican/on-being-approximate-an-inadvertent-data-poem.html" rel="alternate"></link><updated>2013-07-20T05:39:00+02:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2013-07-20:on-being-approximate-an-inadvertent-data-poem.html</id><summary type="html">&lt;html&gt;&lt;body&gt;&lt;p&gt;&lt;img alt="An inadvertent data poem" src="http://justmytwospence.github.com/pelican/images/on-being-approximate.png" style="width: 1024px; height: auto; max-width: 100%;"/&gt;&lt;/p&gt;
&lt;p&gt;An inadvertent data poem by &lt;a href="http://www.usfca.edu/facultydetails.aspx?id=6442485442"&gt;Dr. Cindi Thompson&lt;/a&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;</summary><category term="approximation"></category></entry><entry><title>D3 Test</title><link href="http://justmytwospence.github.com/pelican/d3-test.html" rel="alternate"></link><updated>2013-03-21T00:00:00+01:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2013-03-21:d3-test.html</id><summary type="html">&lt;html&gt;&lt;body&gt;&lt;button class="btn btn-info" id="add"&gt;
		Add
	&lt;/button&gt;
&lt;button class="btn btn-info" id="remove"&gt;
		Remove
	&lt;/button&gt;
&lt;div id="svg"&gt;&lt;/div&gt;
&lt;/body&gt;&lt;/html&gt;</summary></entry><entry><title>Science: the art and arborization of knowledge</title><link href="http://justmytwospence.github.com/pelican/science-the-art-and-arborization-of-knowledge.html" rel="alternate"></link><updated>2011-10-06T06:27:00+02:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2011-10-06:science-the-art-and-arborization-of-knowledge.html</id><summary type="html">&lt;html&gt;&lt;body&gt;&lt;p&gt;I often find it odd that people tend to think of “science” as being somehow classified exclusively from “humanities.” Somehow things like literature, history, and philosophy become the study of the human condition while science becomes simply technobabble ruled by equations and esoteric to the point of being completely inaccesible to anyone that hasn’t spent their life chiseling away at their little block of science.&lt;/p&gt;
&lt;p&gt;But in this era of scientific ultra-specialization, its easy to lose sight of the fact that there is nothing more fundamentally human. Science isn’t a set of equations, the latest &lt;span class="caps"&gt;MRI&lt;/span&gt; scanner, deep-space telescope, or vat of chemicals. In its purest essence, science is a way for us to discover what &lt;em&gt;is.&lt;/em&gt; Actually, it’s the &lt;em&gt;only&lt;/em&gt; way for us to explore truth. There is no other tool available to us- which is why science strikes me as the fundamental study of the human condition and our place in the universe.&lt;/p&gt;
&lt;p&gt;In this respect, science is &lt;em&gt;simple.&lt;/em&gt;Its interesting to note that most of the pivotal, truly &lt;em&gt;insightful&lt;/em&gt;revelations that scientists have dreamed up are so basic a child can understand them immediately. Take, for example, Darwin’s theory of evolution. This is (only somewhat) arguably the most important and unifying principle in all of biology (and perhaps the physical sciences as well, see: &lt;a href="http://www.ted.com/talks/lee_cronin_making_matter_come_alive.html"&gt;Lee Cronin&lt;/a&gt;), but it barely requires an ounce more knowledge than what is plainly available to everyone. Okay, well it did take some island hopping and careful observations, but now that the insight is made, its intuitive. Science is a way of looking at the way things are and gaining both incredible power and profound meaning from it.&lt;/p&gt;
&lt;p&gt;Similarly, while Einstein’s theories of relativity may seem stymying and even intimidating, whats truly amazing is that the conclusions they draw can be (and originally were!) arrived at purely on the basis of thought experiments! Think about that. SImply by changing the way that we &lt;em&gt;conceive&lt;/em&gt; of the things we experience, we can create understanding where there was once nothing.&lt;/p&gt;
&lt;p&gt;Do these kinds of insights still happen in science? Sometimes if feels like there’s no way we will make comparable discoveries in our lifetime. Surely we aren’t still missing something as big and far-reaching as evolution or E=mc\^2… Brain science is one of the few fields of inquiry left in which such a paradigm shift can be made. Its my belief that the seemingly intractable problems of consciousness- of what “we” and our subjective experiences even &lt;em&gt;are-&lt;/em&gt;can and will be enlightened by science. Like evolution and relativity, all it requires is the right way of looking at the issue.&lt;/p&gt;
&lt;p&gt;Of course, its entirely neuro-chauvinistic of me to make such a special claim about the brain. After all, we don’t know what we don’t know, and thats why we have science.&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;</summary><category term="humanities"></category><category term="paradigm"></category><category term="philosophy"></category><category term="science"></category></entry><entry><title>Modern hierarchy of needs</title><link href="http://justmytwospence.github.com/pelican/one-of-my-major-life-goals-is-to-have-my-own-ted.html" rel="alternate"></link><updated>2011-10-03T03:17:00+02:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2011-10-03:one-of-my-major-life-goals-is-to-have-my-own-ted.html</id><summary type="html">&lt;html&gt;&lt;body&gt;&lt;p&gt;[gallery]&lt;/p&gt;
&lt;p&gt;One of my major life goals is to have my own &lt;span class="caps"&gt;TED&lt;/span&gt; talk. In fact, I’m pretty sure if Maslow had been doing his research today, the pinnacle of self-actualization atop his hierarchy of needs would look something like this.&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;</summary><category term="Hierarchy of needs"></category><category term="ideas worth spreading"></category><category term="Maslow"></category><category term="TED"></category></entry><entry><title>Thielfoundation.org</title><link href="http://justmytwospence.github.com/pelican/thielfoundation-org.html" rel="alternate"></link><updated>2011-09-26T03:58:00+02:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2011-09-26:thielfoundation-org.html</id><summary type="html">&lt;html&gt;&lt;body&gt;&lt;p&gt;&lt;a href="http://www.thielfoundation.org/index.php?option=com_content&amp;amp;id=14:the-thiel-fellowship-20-under-20&amp;amp;catid=1&amp;amp;Itemid=16"&gt;Thielfoundation.org&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;About a week ago, my house-mate invited me to has to have been one of the most interesting social events I’ve ever lucked into attending. The founder of Paypal, subsequent multimillion(billion?)aire, and venture capitalist Peter Thiel created a foundation that offers fellowships that amount to anti-college scholarships. Under the program name 20 under 20, he provides brilliant, successful, creative teens with 100,000 dollars over the course of two years to &lt;span class="caps"&gt;NOT&lt;/span&gt; go to Ivy League schools and, instead, become entrepreneurs and and develop their ideas. They must have had some great applications because in their first year, the foundation couldn’t settle on 20 and so there’s something like 23 or 24 in actuality. &lt;/p&gt;
&lt;p&gt;Incredible premise, you might say. And incredible it is.&lt;/p&gt;
&lt;p&gt;My aforementioned house-mate (I haven’t decided if I am going to use real names in this blog yet) has somehow fallen in a few of the fellows, and let me tag along to a social get-together of the foundation. It took place right on the Bay in the Berkeley marina, surrounded by towering sailboats docked on shore.&lt;/p&gt;
&lt;p&gt;We got there fairly late, but during the time that we were there we sure met some interesting characters. My housemate introduced me to a leader in the “seasteading” movement- which is an effort to develop offshore sovereign communities outside of any existing federal jurisdiction in an effort to establish and test alternative, highly libertarian societal structures. Or something like that. In addition, I was brought up to speed on the status of the first “charter cities” being created in Honduras. There is a fantastic &lt;span class="caps"&gt;TED&lt;/span&gt; talk concerning these charter cities that I highly recommend. &lt;/p&gt;
&lt;p&gt;That conversation led us into a discussion with a gentleman about the possibilities such a city would present for medical tourism. Eventually it was discovered that he works for a cryogenics biotech company, and actually used to be the president of Alcor Life Extension Foundation. I’ve been interested in Alcor for a while because its such a controversial and fascinating idea- they will chemically and cryogenically preserve your body (or just your head- if you are on a budget) after death so that if and when we develop technologies to reinstate neural activity, you’ll still be there to do so. This of course raises a whole host of interesting philosophical issues, like what kind of role continuity of neural activity plays in the issue of consciousness or identity, if any. Maybe another blog post on that some day soon.&lt;/p&gt;
&lt;p&gt;Later I met someone working on developing models of brain function in the human neocortex. One of their key premises is that we can create these models in any way we want as long as we successfully mimic the output of the brain, but I happen to disagree on this point. Modeling true intelligence is more than just mimicking output, the &lt;em&gt;way&lt;/em&gt; in which computation is performed is nontrivial. Apparently, another company in the Bay area is taking exactly this approach. Numenta was founded by Jeff Hawkins, the guy who invented Palm Pilot, and is developing cortical learning algorithms that are based on actual biology- much more meaningful in my opinion. I’m in the process of reading everything about Numenta’s work at the moment, and I highly recommend Jeff Hawkins’ &lt;span class="caps"&gt;TED&lt;/span&gt; talk as well if you are at all interested in &lt;span class="caps"&gt;AI&lt;/span&gt;, the brain, or intelligence. There will definitely be another blog post in the near future concerning this.&lt;/p&gt;
&lt;p&gt;Oh, and we almost got abducted by a taco truck. We were both starving and heard the food truck was about to leave, so we ran out to it, but it looked closed up. Several people were climbing in the side door however, so we followed them in hunger-fueled desperation, only to find the door closed behind us. Apparently these other people just needed a ride back to San Fran and were hitchhiking on the truck, but fortunately we managed to bail out before we wound up as unwitting taco-making indentured servants.&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;</summary><category term="entrepeneurship"></category><category term="silicon valley"></category></entry><entry><title>Nonlinear</title><link href="http://justmytwospence.github.com/pelican/nonlinear.html" rel="alternate"></link><updated>2011-09-25T00:59:00+02:00</updated><author><name>Spencer Boucher</name></author><id>tag:justmytwospence.github.com/pelican,2011-09-25:nonlinear.html</id><summary type="html">&lt;html&gt;&lt;body&gt;&lt;p&gt;If there is one thing I have learned since graduating from college, it is that life is not linear. I feel that high school, college, and social constructions I have grown up in had programmed me to conceive of life in a very stepwise, linear way. Maybe it’s because you are working so single-mindedly toward holding that diploma in your hand. Or perhaps because you just don’t have much exposure beyond the people who are doing mostly what you are doing. I could be wrong, but I think a lot of college kids have this mentality.&lt;/p&gt;
&lt;p&gt;But it just isn’t. Or at least it doesn’t have to be if you don’t want it to be. You can do absolutely anything you want to in this world, and the arena is &lt;span class="caps"&gt;HUGE&lt;/span&gt;. Like, unimaginably huge. And the Bay Area has to be one of the most incredible places in the world to make this fact hit home. My new home is a mecca for so many different cultural movements. Silicon Valley, entrepeneurs, artists, hippies, &lt;span class="caps"&gt;LGBT&lt;/span&gt; communities, futurists, libertarians, and of course scientists, the last of which I’d like to think I fall into.&lt;/p&gt;
&lt;p&gt;My favorite thing about moving here by far is simply how &lt;em&gt;interesting&lt;/em&gt; everyone I meet is. I mean really really fascinating. Maybe I’ve just been somehow missing how intrinsically awesome the random people I would meet in Tennessee and Houston were. But here, in a single night you can meet people who work for Google and Facebook, people who hunt planets for &lt;span class="caps"&gt;NASA&lt;/span&gt;, people crafting all manner of crazy or thoughtful or brilliant startups, people who have attended universities all over the country and the world… I could go on and on. &lt;/p&gt;
&lt;p&gt;That’s one thing I hope to do with this blog: highlight the amazing people and projects that I come across. These people are not living linear lives. And just being in this crazy, fast paced, marvelously jumbled community is creating a paradigm shift in the way that I see the world. Its tough to explain, but I guess I’m realizing how things are out there for you to take and affect and become a part of- &lt;em&gt;big&lt;/em&gt; things- and all you have to do is try. The rough plan for this blog is to make it about &lt;strong&gt;ideas&lt;/strong&gt;, &lt;strong&gt;adventures&lt;/strong&gt;, and &lt;strong&gt;discoveries&lt;/strong&gt;. No promises for how it will turn out developing though.&lt;/p&gt;
&lt;p&gt;Here’s to being nonlinear!&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;</summary></entry></feed>