<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>justmytwospence</title><link href="http://spencerboucher.com/" rel="alternate"></link><link href="http://spencerboucher.com/feeds/vizualization.atom.xml" rel="self"></link><id>http://spencerboucher.com/</id><updated>2014-03-21T00:00:00-07:00</updated><entry><title>D3 Test</title><link href="http://spencerboucher.com/d3-test.html" rel="alternate"></link><updated>2014-03-21T00:00:00-07:00</updated><author><name>Spencer Boucher</name></author><id>tag:spencerboucher.com,2014-03-21:d3-test.html</id><summary type="html">

	&lt;p&gt;To test my ability to embed D3.js visualizations into my blog, I present to you basically my first D3 graph. Its basically the one that Scott Murray walks you through in his book &lt;a href="http://chimera.labs.oreilly.com/books/1230000000345" target="_blank"&gt;Interactive Data Visualization for the Web&lt;/a&gt;. I highly recommend it for all skill&amp;nbsp;levels!&lt;/p&gt;

	&lt;div style="text-align: center; margin-top: 20px"&gt;
		&lt;div class="btn-group btn-group-lg text-center"&gt;
			&lt;button id="add" class="btn btn-primary"&gt;Add&lt;/button&gt;
			&lt;button id="remove" class="btn btn-primary"&gt;Remove&lt;/button&gt;
	&lt;/div&gt;

	&lt;div id="svg"&gt;&lt;/div&gt;

</summary></entry><entry><title>Scheduling tasks in the cloud with EC2 APIs</title><link href="http://spencerboucher.com/ec2-apis.html" rel="alternate"></link><updated>2014-01-12T17:53:00-08:00</updated><author><name>Spencer Boucher</name></author><id>tag:spencerboucher.com,2014-01-12:ec2-apis.html</id><summary type="html">&lt;p&gt;This post is sort of an addendum to our &lt;a href="http://www.spencerboucher.com/live-mapping/" title="Live mapping"&gt;live-mapping project&lt;/a&gt;, but it should also be of use to anyone looking to run an arbitrary script on a recurring schedule. Originally, we set up a 24/7 instance on &lt;a href="http://aws.amazon.com/ec2/"&gt;Amazon&amp;#8217;s Elastic Compute Cloud&lt;/a&gt; that ran a daily &lt;code&gt;cron&lt;/code&gt; job. This works, but its a bit wasteful because we&amp;#8217;re paying for 24 hours of cloud even though we&amp;#8217;re only actually using it for maybe 5 minutes a&amp;nbsp;day.  &lt;/p&gt;
&lt;p&gt;Fortunately, Amazon provides a &lt;a href="http://aws.amazon.com/developertools/"&gt;schmorgesborg&lt;/a&gt; of command line interface (&lt;span class="caps"&gt;CLI&lt;/span&gt;) tools that allow us to manage our cloud instances more efficiently. Specifically, we want to schedule an instance to spin up only once a day, execute our script, then shut back down. To accomplish this, we will want three &lt;span class="caps"&gt;CLI&lt;/span&gt; tools: &lt;a href="http://aws.amazon.com/developertools/368"&gt;the Amazon &lt;span class="caps"&gt;EC2&lt;/span&gt; &lt;span class="caps"&gt;AMI&lt;/span&gt; Tools&lt;/a&gt;, &lt;a href="http://aws.amazon.com/developertools/351"&gt;the Amazon &lt;span class="caps"&gt;EC2&lt;/span&gt; &lt;span class="caps"&gt;API&lt;/span&gt; Tools&lt;/a&gt;,and &lt;a href="http://aws.amazon.com/developertools/2535"&gt;the Auto Scaling Command Line Tool&lt;/a&gt;. If you&amp;#8217;re on a Mac, it&amp;#8217;s way easier to get these with &lt;a href="http://brew.sh/"&gt;Homebrew&lt;/a&gt; than by downloading from Amazon&amp;#8217;s&amp;nbsp;website:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;brew install ec2-ami-tools &lt;span class="c"&gt;# For creating an AMI from an existing machine&lt;/span&gt;
brew install ec2-api-tools &lt;span class="c"&gt;# For registering and launching instances&lt;/span&gt;
brew install aws-as        &lt;span class="c"&gt;# For creating auto scaling groups / defining schedules&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;As an extra Homebrew bonus, running &lt;code&gt;brew info ec2-ami-tools&lt;/code&gt;, &lt;code&gt;brew info ec2-api-tools&lt;/code&gt;, and &lt;code&gt;brew info aws-as&lt;/code&gt; will now tell us exactly what we need to do to get our authentication and environment variables all set up. First we are told to download the necessary .pem files from &lt;a href="http://aws-portal.amazon.com/gp/aws/developer/account/index.html?action=access-key"&gt;this Amazon page&lt;/a&gt; and place them into a new hidden directory of our home directory &lt;code&gt;.ec2&lt;/code&gt;. Then we tell our command line where everything lives now by inserting the following lines into our &lt;code&gt;.bashrc&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nb"&gt;export &lt;/span&gt;&lt;span class="nv"&gt;EC2_PRIVATE_KEY&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;$(/bin/ls &amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$HOME&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;/.ec2/pk-*.pem | /usr/bin/head -1)&amp;quot;&lt;/span&gt;
&lt;span class="nb"&gt;export &lt;/span&gt;&lt;span class="nv"&gt;EC2_CERT&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;$(/bin/ls &amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$HOME&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;/.ec2/cert-*.pem | /usr/bin/head -1)&amp;quot;&lt;/span&gt;
&lt;span class="nb"&gt;export &lt;/span&gt;&lt;span class="nv"&gt;EC2_HOME&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;/usr/local/Cellar/ec2-api-tools/1.6.12.0/libexec&amp;quot;&lt;/span&gt;
&lt;span class="nb"&gt;export &lt;/span&gt;&lt;span class="nv"&gt;AWS_AUTO_SCALING_HOME&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;/usr/local/Cellar/auto-scaling/1.0.61.4/libexec&amp;quot;&lt;/span&gt;
&lt;span class="nb"&gt;export &lt;/span&gt;&lt;span class="nv"&gt;EC2_AMITOOL_HOME&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;/usr/local/Cellar/ec2-ami-tools/1.4.0.9/libexec&amp;quot;&lt;/span&gt;
&lt;span class="nb"&gt;export &lt;/span&gt;&lt;span class="nv"&gt;EC2_REGION&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;us-west-2&amp;quot;&lt;/span&gt;
&lt;span class="nb"&gt;export &lt;/span&gt;&lt;span class="nv"&gt;EC2_ZONE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;EC2_REGION&lt;/span&gt;&lt;span class="k"&gt;}&lt;/span&gt;a
&lt;span class="nb"&gt;export &lt;/span&gt;&lt;span class="nv"&gt;EC2_URL&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;https://&lt;span class="nv"&gt;$EC2_REGION&lt;/span&gt;.ec2.amazonaws.com
&lt;span class="nb"&gt;export &lt;/span&gt;&lt;span class="nv"&gt;AWS_AUTO_SCALING_URL&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;https://autoscaling.&lt;span class="nv"&gt;$EC2_REGION&lt;/span&gt;.amazonaws.com
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Its pretty simple, but if you have any trouble with this part, refer to the official &lt;a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/SettingUp_CommandLine.html"&gt;Amazon documentation for setting up the command line&lt;/a&gt;.  &lt;/p&gt;
&lt;p&gt;Because these environment variables are recognized out of the box by the &lt;span class="caps"&gt;CLI&lt;/span&gt; tools, we won&amp;#8217;t need to point to our authentication keys or specify a region every time we make an &lt;span class="caps"&gt;API&lt;/span&gt; call and our next commands will be much more succinct. Note that every &lt;span class="caps"&gt;EC2&lt;/span&gt; instance is physically located at one of several regions; we are using us-west-2 because it happens to be where I spun up the existing instance that currently holds our &amp;#8220;update.py&amp;#8221; script, but any of them would probably work just fine for the simple job at&amp;nbsp;hand.  &lt;/p&gt;
&lt;table&gt;
  &lt;tr&gt;
    &lt;th&gt;Code&lt;/th&gt;
    &lt;th&gt;Region&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;ap-northeast-1&lt;/td&gt;
    &lt;td&gt; Asia Pacific (Tokyo) Region&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;ap-southeast-1&lt;/td&gt;
    &lt;td&gt;Asia Pacific (Singapore) Region&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;ap-southeast-2&lt;/td&gt;
    &lt;td&gt;Asia Pacific (Sydney) Region&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;eu-west-1&lt;/td&gt;
    &lt;td&gt;&lt;span class="caps"&gt;EU&lt;/span&gt; (Ireland) Region&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;sa-east-1&lt;/td&gt;
    &lt;td&gt;South America (Sao Paulo) Region&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;us-east-1&lt;/td&gt;
    &lt;td&gt;&lt;span class="caps"&gt;US&lt;/span&gt; East (Northern Virginia) Region&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;us-west-1&lt;/td&gt;
    &lt;td&gt;&lt;span class="caps"&gt;US&lt;/span&gt; West (Northern California) Region&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;us-west-2&lt;/td&gt;
    &lt;td&gt;&lt;span class="caps"&gt;US&lt;/span&gt; West (Oregon) Region&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;So, first things first. We can&amp;#8217;t just spin up an off-the-rack &lt;span class="caps"&gt;EC2&lt;/span&gt; instance every day, because we&amp;#8217;ll run into the same problem that I originally had with my web host: the Python modules that we need won&amp;#8217;t be installed. We &lt;em&gt;could&lt;/em&gt; write a script that would install &lt;code&gt;pip&lt;/code&gt; plus all of the requisite Python modules and run it first thing after we launch the instance, but there&amp;#8217;s a better&amp;nbsp;way:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;ec2-create-image i-8918e1be -n &lt;span class="s2"&gt;&amp;quot;Map Update Image&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This command from &lt;code&gt;ec2-ami-tools&lt;/code&gt; creates an &amp;#8220;Amazon Machine Image&amp;#8221; of the instance that we previously had running and names it &amp;#8220;Map Update Image&amp;#8221;. A new image &lt;span class="caps"&gt;ID&lt;/span&gt; will now print to your console, &lt;code&gt;ami-fcdfb9cc&lt;/code&gt; in my case. This is tantamount to cloning the instance, because we can now reference the new image &lt;span class="caps"&gt;ID&lt;/span&gt; when we spin up new instances and all of our modules, scripts, etc. will be there waiting for us. Note that I removed the instance&amp;#8217;s &lt;code&gt;cron&lt;/code&gt; job &lt;em&gt;before&lt;/em&gt; creating the &lt;span class="caps"&gt;AMI&lt;/span&gt;, because we&amp;#8217;ll now be handling the task scheduling from &lt;em&gt;outside&lt;/em&gt; the instance, via &lt;strong&gt;autoscaling&lt;/strong&gt;.  &lt;/p&gt;
&lt;p&gt;Next let&amp;#8217;s write a shell script that will execute our Python map-updating script, shoot us a diagnostic email, then shut down the instance that its running on. The idea here is that once a day we&amp;#8217;re going to spin up an instance using our shiny new &lt;span class="caps"&gt;AMI&lt;/span&gt; and immediately run this new script (let&amp;#8217;s call it &amp;#8220;update.sh&amp;#8221;) that will do its business and then promptly commit seppuku and stop charging us money. Eric Hammond has created a great template on &lt;a href="http://alestic.com/2011/11/ec2-schedule-instance"&gt;his blog&lt;/a&gt;, which I&amp;#8217;ve modified below. Note the execution of our &lt;a href="http://www.spencerboucher.com/live-mapping/" title="Live mapping"&gt;familiar&lt;/a&gt; &amp;#8220;update.py&amp;#8221; script highlighted on line 4, and the apoptosis command on line&amp;nbsp;46:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;#!/bin/bash -x&lt;/span&gt;
&lt;span class="nb"&gt;exec&lt;/span&gt; &amp;gt; &amp;gt;&lt;span class="o"&gt;(&lt;/span&gt;tee /var/log/user-data.log|logger -t user-data -s 2&amp;gt;/dev/console&lt;span class="o"&gt;)&lt;/span&gt; 2&amp;gt;&amp;amp;1

/usr/bin/python /home/ubuntu/update.py &lt;span class="c"&gt;# Run the script&lt;/span&gt;

&lt;span class="nv"&gt;EMAIL&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;spencer.g.boucher@gmail.com

&lt;span class="c"&gt;# Upgrade and install Postfix so we can send a sample email&lt;/span&gt;
&lt;span class="nb"&gt;export &lt;/span&gt;&lt;span class="nv"&gt;DEBIAN_FRONTEND&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;noninteractive
apt-get update &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; apt-get upgrade -y &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; apt-get install -y postfix

&lt;span class="c"&gt;# Get some information about the running instance&lt;/span&gt;
&lt;span class="nv"&gt;instance_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;wget -qO- instance-data/latest/meta-data/instance-id&lt;span class="k"&gt;)&lt;/span&gt;
&lt;span class="nv"&gt;public_ip&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;wget -qO- instance-data/latest/meta-data/public-ipv4&lt;span class="k"&gt;)&lt;/span&gt;
&lt;span class="nv"&gt;zone&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;wget -qO- instance-data/latest/meta-data/placement/availability-zone&lt;span class="k"&gt;)&lt;/span&gt;
&lt;span class="nv"&gt;region&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;expr match &lt;span class="nv"&gt;$zone&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;\(.*\).&amp;#39;&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;
&lt;span class="nv"&gt;uptime&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;uptime&lt;span class="k"&gt;)&lt;/span&gt;

&lt;span class="c"&gt;# Send status email&lt;/span&gt;
/usr/sbin/sendmail -oi -t -f &lt;span class="nv"&gt;$EMAIL&lt;/span&gt; &lt;span class="s"&gt;&amp;lt;&amp;lt;EOM&lt;/span&gt;
&lt;span class="s"&gt;From: $EMAIL&lt;/span&gt;
&lt;span class="s"&gt;To: $EMAIL&lt;/span&gt;
&lt;span class="s"&gt;Subject: Results of EC2 scheduled script&lt;/span&gt;

&lt;span class="s"&gt;This email message was generated on the following EC2 instance:&lt;/span&gt;

&lt;span class="s"&gt;  instance id: $instance_id&lt;/span&gt;
&lt;span class="s"&gt;  region:      $region&lt;/span&gt;
&lt;span class="s"&gt;  public ip:   $public_ip&lt;/span&gt;
&lt;span class="s"&gt;  uptime:      $uptime&lt;/span&gt;

&lt;span class="s"&gt;If the instance is still running, you can monitor the output of this&lt;/span&gt;
&lt;span class="s"&gt;job using a command like:&lt;/span&gt;

&lt;span class="s"&gt;  ssh ubuntu@$public_ip tail -1000f /var/log/user-data.log&lt;/span&gt;

&lt;span class="s"&gt;  ec2-describe-instances --region $region $instance_id&lt;/span&gt;

&lt;span class="s"&gt;EOM&lt;/span&gt;

&lt;span class="c"&gt;# Give the script and email some time to do their thing&lt;/span&gt;
sleep 600 &lt;span class="c"&gt;# 10 minutes&lt;/span&gt;

&lt;span class="c"&gt;# This will stop the EBS boot instance, stopping the hourly charges.&lt;/span&gt;
&lt;span class="c"&gt;# Have Auto Scaling terminate it, stopping the storage charges.&lt;/span&gt;
shutdown -h now

&lt;span class="nb"&gt;exit &lt;/span&gt;0
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Note that the user data script that we pass to the launch configuration executes with &lt;em&gt;root&lt;/em&gt; permissions, not as the user &amp;#8220;ubuntu&amp;#8221; that you would typically log in as via &lt;code&gt;ssh&lt;/code&gt;. Its probably best to be as explicit as possible when specifying path names in the cloud, the tilde operator might turn around and bite&amp;nbsp;you.  &lt;/p&gt;
&lt;p&gt;Now we need to create &lt;strong&gt;launch configuration&lt;/strong&gt; that will basically do all the button-pushing that we would normally be doing at the &lt;span class="caps"&gt;AWS&lt;/span&gt; console &lt;span class="caps"&gt;GUI&lt;/span&gt;.  &lt;/p&gt;
&lt;p&gt;Here we&amp;nbsp;specify:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;Micro&amp;#8221; as our instance&amp;nbsp;type.&lt;/li&gt;
&lt;li&gt;Our shell script &amp;#8220;update.sh&amp;#8221; from step 2 as the &amp;#8220;user-data-file&amp;#8221;. User data files are passed into the instance and executed immediately when supplied in the launch configuration. They must be less than 16kb as I suppose they are stored on some ancillary server&amp;nbsp;somewhere.&lt;/li&gt;
&lt;li&gt;The &lt;span class="caps"&gt;AMI&lt;/span&gt; image that we cloned in step 1 from the instance that included our Python&amp;nbsp;modules.&lt;/li&gt;
&lt;li&gt;The name of the launch config; let&amp;#8217;s call it&amp;nbsp;&amp;#8220;map-update-launch-config&amp;#8221;.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;as-create-launch-config
   --instance-type t1.micro
   --user-data-file ~/Desktop/update.sh
   --image-id ami-fcdfb9cc
   --launch-config &lt;span class="s2"&gt;&amp;quot;map-update-launch-config&amp;quot;&lt;/span&gt;
as-describe-launch-configs --headers
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Note that the second line provides a list of all the launch configurations that have been&amp;nbsp;created.  &lt;/p&gt;
&lt;p&gt;We must also create an &lt;strong&gt;auto scaling group&lt;/strong&gt;. These are typically used as a sort of container to which we can add/remove instances on a schedule or in response to heavy traffic, but we can also use it to schedule a single instance to flick on and off. We need to tell&amp;nbsp;it:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A name to assign the scaling group&amp;nbsp;(&amp;#8220;map-update-scale-group&amp;#8221;).&lt;/li&gt;
&lt;li&gt;The name of the launch configuration we created in step 3&amp;nbsp;(&amp;#8220;map-update-launch-config&amp;#8221;).&lt;/li&gt;
&lt;li&gt;Which availability zone we want to use (basically irrelevant; we set our environment variable &lt;code&gt;EC2_ZONE&lt;/code&gt; to &amp;#8220;a&amp;#8221; earlier). &lt;code&gt;ec2-describe-available-zones&lt;/code&gt; provides a list of the available&amp;nbsp;zones&lt;/li&gt;
&lt;li&gt;A minimum and maximum number of instances in the group. We&amp;#8217;ll initialize these to&amp;nbsp;zero.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;as-create-auto-scaling-group
   --auto-scaling-group &lt;span class="s2"&gt;&amp;quot;map-update-scale-group&amp;quot;&lt;/span&gt;
   --launch-configuration &lt;span class="s2"&gt;&amp;quot;map-update-launch-config&amp;quot;&lt;/span&gt;
   --availability-zones &lt;span class="s2"&gt;&amp;quot;$EC2_ZONE&amp;quot;&lt;/span&gt;
   --min-size 0 --max-size 0
as-suspend-processes &lt;span class="s2"&gt;&amp;quot;map-update-scale-group&amp;quot;&lt;/span&gt;
   --processes ReplaceUnhealthy
as-describe-auto-scaling-groups --headers
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In the second line, we are using &lt;code&gt;as-suspend-processes&lt;/code&gt; to prevent the instance&amp;#8217;s default behavior which is to attempt to restart after it is shut down. The third line provides a list of all the auto scaling groups that have been&amp;nbsp;created.  &lt;/p&gt;
&lt;p&gt;Last but not least, we are ready to assign a schedule to our auto scaling group. Here we create two: one to start the instance and one to terminate the instance. Astute readers will recall that &amp;#8220;update.sh&amp;#8221; already &lt;em&gt;stops&lt;/em&gt; the instance so that we aren&amp;#8217;t paying to have it running, but we also need to completely &lt;em&gt;terminate&lt;/em&gt; the instance so that we aren&amp;#8217;t paying to store information about it. Each schedule&amp;nbsp;requires:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A name (&amp;#8220;map-update-start&amp;#8221; &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt;&amp;nbsp;&amp;#8220;map-update-stop&amp;#8221;).&lt;/li&gt;
&lt;li&gt;The name of the auto scaling group we created in step 4&amp;nbsp;(&amp;#8220;map-update-scale-group&amp;#8221;).&lt;/li&gt;
&lt;li&gt;How we want to scale. By setting both &lt;code&gt;min-size&lt;/code&gt; and &lt;code&gt;max-size&lt;/code&gt; to 1, we are effectively turning on one instance. We later effectively turn that instance back off by setting both to&amp;nbsp;0.&lt;/li&gt;
&lt;li&gt;A &amp;#8220;recurrence,&amp;#8221; ie when to occur. This flag uses the same syntax that &lt;code&gt;cron&lt;/code&gt; does. Here we set the instance to launch at midnight &lt;span class="caps"&gt;UTC&lt;/span&gt; (&lt;code&gt;0 0 * * *&lt;/code&gt;), and terminate 15 minutes later (&lt;code&gt;15 0 * * *&lt;/code&gt;). Recall that our script already stops the instance 10 minutes after execution, so 15 minutes is playing it&amp;nbsp;safe.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;as-put-scheduled-update-group-action
   --name &lt;span class="s2"&gt;&amp;quot;map-update-start&amp;quot;&lt;/span&gt;
   --auto-scaling-group &lt;span class="s2"&gt;&amp;quot;map-update-scale-group&amp;quot;&lt;/span&gt;
   --min-size 1 --max-size 1
   --recurrence &lt;span class="s2"&gt;&amp;quot;0 0 * * *&amp;quot;&lt;/span&gt;
as-put-scheduled-update-group-action
   --name &lt;span class="s2"&gt;&amp;quot;map-update-stop&amp;quot;&lt;/span&gt;
   --auto-scaling-group &lt;span class="s2"&gt;&amp;quot;map-update-scale-group&amp;quot;&lt;/span&gt;
   --min-size 0 --max-size 0
   --recurrence &lt;span class="s2"&gt;&amp;quot;15 0 * * *&amp;quot;&lt;/span&gt;
as-describe-scheduled-actions --headers
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;As before, the third line provides a list of the actions that have been&amp;nbsp;scheduled.  &lt;/p&gt;
&lt;p&gt;And thats it! We are now only paying for 10 or 15 minutes of cloud per day, as opposed to 1,440 of them. To review the timeline we have created in this example: our auto scaling group boots up an instance up at midnight &lt;span class="caps"&gt;UTC&lt;/span&gt; that immediately executes &amp;#8220;update.sh&amp;#8221;. This automatically executes &amp;#8220;update.py&amp;#8221; and shoots us a diagnostic email. It then waits 10 minutes to make sure everything has time to run, before stopping the instance. 5 minutes after &lt;em&gt;that&lt;/em&gt; the auto scaling group then completely terminates the&amp;nbsp;instance.  &lt;/p&gt;
&lt;p&gt;Other great&amp;nbsp;resources:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://docs.aws.amazon.com/AutoScaling/latest/DeveloperGuide/schedule_time.html"&gt;Official Amazon documentation for scheduling auto scaling&amp;nbsp;groups&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://alestic.com/2011/11/ec2-schedule-instance"&gt;Running &lt;span class="caps"&gt;EC2&lt;/span&gt; Instances on a Recurring Schedule with Auto&amp;nbsp;Scaling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.robertsindall.co.uk/blog/how-to-use-amazons-auto-scaling-groups/"&gt;Summary of &lt;span class="caps"&gt;API&lt;/span&gt;&amp;nbsp;commands&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.cardinalpath.com/autoscaling-your-website-with-amazon-web-services-part-2/"&gt;Auto Scaling Your Website with Amazon Web&amp;nbsp;Services&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</summary><category term="api"></category><category term="auto scaling"></category><category term="aws"></category><category term="cloud"></category><category term="cron"></category><category term="ec2"></category></entry><entry><title>Live mapping</title><link href="http://spencerboucher.com/live-mapping.html" rel="alternate"></link><updated>2014-01-08T08:50:00-08:00</updated><author><name>Spencer Boucher</name></author><id>tag:spencerboucher.com,2014-01-08:live-mapping.html</id><summary type="html">&lt;p&gt;I&amp;#8217;ve been wanting to do some more mapping stuff since my first encounter with Leaflet a month or two ago while I was working on a project for &lt;a href="http://auto-grid.com"&gt;AutoGrid&lt;/a&gt;. I had my eye on CartoDB&amp;#8217;s time series library, &lt;a href="https://github.com/cartodb/torque"&gt;Torque&lt;/a&gt;, because I had really wanted to do some time-series visualization, but time constraints and privacy issues with uploading data to CartoDB&amp;#8217;s servers prevented me from really exploring. Since I had a few days of free time over winter break, I played around with it a bit and came up with this: &lt;a href="http://www.spencerboucher.com/map"&gt;spencerboucher.com/map&lt;/a&gt;. How&amp;#8217;d I do&amp;nbsp;it?  &lt;/p&gt;
&lt;p&gt;First I needed some geographic data, so I turned to a source of data I&amp;#8217;ve been collected for almost a year - my own location. &lt;a href="http://openpaths.cc"&gt;OpenPaths&lt;/a&gt; is a mobile app that records your location at regular time intervals. I opted for every 30 minutes at first, then upped it to every 15 minutes when I discovered that the effect on battery life wasn&amp;#8217;t nearly as bad as I expected it to be. OpenPaths is a project of &lt;a href="http://nytlabs.com/"&gt;the R&amp;amp;D department at The New York Times&lt;/a&gt; and they &lt;a href="https://openpaths.cc/FAQ"&gt;claim&lt;/a&gt; that you are the only one with access to the collected data. Interestingly, you can grant various &lt;a href="https://openpaths.cc/projects"&gt;research programs&lt;/a&gt; access to your data at your own discretion. Your data is conveniently downloadable as a csv, json, or kml file, so I easily pulled my dataset of \~3,000 time points since December 2012. Unfortunately, I made the switch from iPhone to Android around April (well, that part is fortunate), and forgot to re-download the app, so I only really have data from the around the first three months and last two months of&amp;nbsp;2013.  &lt;/p&gt;
&lt;p&gt;Turns out, making impressive maps with CartoDB is almost embarrassingly easy. Their &lt;span class="caps"&gt;GUI&lt;/span&gt; is pretty intuitive and running queries on their postgreSQL database is simple. Even time series stuff built on the Torque backend is really just point and click. I decided that the best way to visualize this data was with an aggregated hexbin heatmap of all my past locations, overlaid with a point-by-point replay with a time-slider. From there, it was just a one-line &lt;span class="caps"&gt;API&lt;/span&gt; call to host the map on my website (line 30 highlighted below), which is significantly easier than the legwork that went into crafting a Leaflet map&amp;nbsp;&amp;#8220;manually.&amp;#8221;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nt"&gt;&amp;lt;html&amp;gt;&lt;/span&gt;

&lt;span class="nt"&gt;&amp;lt;head&amp;gt;&lt;/span&gt;

  &lt;span class="nt"&gt;&amp;lt;meta&lt;/span&gt; &lt;span class="na"&gt;name=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;viewport&amp;quot;&lt;/span&gt; &lt;span class="na"&gt;content=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;initial-scale=1.0, user-scalable=no&amp;quot;&lt;/span&gt; &lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;

  &lt;span class="nt"&gt;&amp;lt;title&amp;gt;&lt;/span&gt;Location | Spencer&lt;span class="nt"&gt;&amp;lt;/title&amp;gt;&lt;/span&gt;

  &lt;span class="nt"&gt;&amp;lt;link&lt;/span&gt; &lt;span class="na"&gt;rel=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;shortcut icon&amp;quot;&lt;/span&gt; &lt;span class="na"&gt;href=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;http://spencerboucher.com/map/favicon.png&amp;quot;&lt;/span&gt; &lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;link&lt;/span&gt; &lt;span class="na"&gt;rel=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;stylesheet&amp;quot;&lt;/span&gt; &lt;span class="na"&gt;href=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;http://libs.cartocdn.com/cartodb.js/v3/themes/css/cartodb.css&amp;quot;&lt;/span&gt; &lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
  &lt;span class="c"&gt;&amp;lt;!--[if lte IE 8]&amp;gt;&lt;/span&gt;
&lt;span class="c"&gt;    &amp;lt;link rel=&amp;quot;stylesheet&amp;quot; href=&amp;quot;http://libs.cartocdn.com/cartodb.js/v3/themes/css/cartodb.ie.css&amp;quot; /&amp;gt;&lt;/span&gt;
&lt;span class="c"&gt;  &amp;lt;![endif]--&amp;gt;&lt;/span&gt;

  &lt;span class="nt"&gt;&amp;lt;style &lt;/span&gt;&lt;span class="na"&gt;type=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;text/css&amp;quot;&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
      &lt;span class="nt"&gt;html&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;body&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nf"&gt;#map&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
          &lt;span class="k"&gt;margin&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
          &lt;span class="k"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
          &lt;span class="k"&gt;width&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="m"&gt;100&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
          &lt;span class="k"&gt;height&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="m"&gt;100&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
          &lt;span class="k"&gt;background&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;black&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
      &lt;span class="nf"&gt;#cartodb-gmaps-attribution&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="k"&gt;visibility&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="k"&gt;hidden&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;/style&amp;gt;&lt;/span&gt;

  &lt;span class="nt"&gt;&amp;lt;script &lt;/span&gt;&lt;span class="na"&gt;src=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;http://maps.google.com/maps/api/js?v=3.2&amp;amp;sensor=false&amp;quot;&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&amp;lt;/script&amp;gt;&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;script &lt;/span&gt;&lt;span class="na"&gt;src=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;http://libs.cartocdn.com/cartodb.js/v3/cartodb.js&amp;quot;&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&amp;lt;/script&amp;gt;&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;script&amp;gt;&lt;/span&gt;
    &lt;span class="kd"&gt;function&lt;/span&gt; &lt;span class="nx"&gt;init&lt;/span&gt;&lt;span class="p"&gt;(){&lt;/span&gt;
      &lt;span class="nx"&gt;cartodb&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;createVis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;map&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;http://justmytwospence.cartodb.com/api/v2/viz/e8fd87d0-78b3-11e3-a9e9-e7941b6e2df0/viz.json&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;/script&amp;gt;&lt;/span&gt;

&lt;span class="nt"&gt;&amp;lt;/head&amp;gt;&lt;/span&gt;

&lt;span class="nt"&gt;&amp;lt;body&lt;/span&gt; &lt;span class="na"&gt;onload=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;init()&amp;quot;&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;div&lt;/span&gt; &lt;span class="na"&gt;id=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;map&amp;#39;&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&amp;lt;/div&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;/body&amp;gt;&lt;/span&gt;

&lt;span class="nt"&gt;&amp;lt;/html&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This is pretty awesome, but in light of how easy it all was, I was almost disappointed. Can we take it one step further? Let&amp;#8217;s put on our &lt;a href="http://quantifiedself.com/about/"&gt;Quantified Self&lt;/a&gt; hats and set about to make this map &lt;em&gt;live&lt;/em&gt;. There&amp;#8217;s three components to making this happen, so we&amp;#8217;ll step through them one at a time. First we need to access the most recent data from OpenPaths (there&amp;#8217;s an &lt;span class="caps"&gt;API&lt;/span&gt; for that!), and then we need to insert that data into CartoDB&amp;#8217;s database (guess what, there&amp;#8217;s an &lt;span class="caps"&gt;API&lt;/span&gt; for that too). Last but not least, we need to schedule that data transplant to occur on a regular basis. The Unix utility &lt;code&gt;cron&lt;/code&gt; is the canonical tool for this type of thing, so this seemed like a good time to learn how to use&amp;nbsp;it.  &lt;/p&gt;
&lt;p&gt;Python has a reputation for being a great &amp;#8220;glue&amp;#8221; language, so that&amp;#8217;s what we&amp;#8217;ll use to build this&amp;nbsp;script.  &lt;/p&gt;
&lt;p&gt;Programmatically accessing your data from OpenPaths is super simple. This piece of our script is pulled more or less verbatim from &lt;a href="https://openpaths.cc/api"&gt;the OpenPaths &lt;span class="caps"&gt;API&lt;/span&gt; documentation&lt;/a&gt;. Line 21 (highlighted below) is key - this is where we specify which data you want to pull for injection into the CartoDB database. Here we will grab the last 24 hours of data (\~96 readings, if you&amp;#8217;re collecting every 15 minutes like me), getting the results in a nice  &lt;span class="caps"&gt;JSON&lt;/span&gt;-formatted variable named &lt;code&gt;data&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;oauth2&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nn"&gt;time&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nn"&gt;urllib&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nn"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nn"&gt;json&lt;/span&gt;

&lt;span class="n"&gt;ACCESS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;redacted&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;SECRET&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;redacted&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;URL&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;https://openpaths.cc/api/1&amp;#39;&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;build_auth_header&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;method&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;params&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="s"&gt;&amp;#39;oauth_version&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;1.0&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s"&gt;&amp;#39;oauth_nonce&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;oauth2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;generate_nonce&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
        &lt;span class="s"&gt;&amp;#39;oauth_timestamp&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()),&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="n"&gt;consumer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;oauth2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Consumer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ACCESS&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;secret&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;SECRET&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;oauth_consumer_key&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;consumer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt; 
    &lt;span class="n"&gt;request&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;oauth2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Request&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;method&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;method&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;parameters&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;signature_method&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;oauth2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SignatureMethod_HMAC_SHA1&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sign_request&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;signature_method&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;consumer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_header&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;now&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;params&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;start_time&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;now&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;24&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="mi"&gt;60&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="mi"&gt;60&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;end_time&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;now&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="c"&gt;# get the last 24 hours&lt;/span&gt;
&lt;span class="n"&gt;query&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt;?&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;URL&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;urllib&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;urlencode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="c"&gt;#print(query)&lt;/span&gt;
&lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;request&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Request&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;query&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;headers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;build_auth_header&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;URL&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;GET&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;connection&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;urlopen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loads&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;connection&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;readlines&lt;/span&gt;&lt;span class="p"&gt;()))&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dumps&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;indent&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="n"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;HTTPError&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now we need to get our new &lt;code&gt;data&lt;/code&gt; variable into CartoDB&amp;#8217;s postgreSQL server. &lt;a href="http://developers.cartodb.com/documentation/sql-api.html"&gt;CartoDB&amp;#8217;s &lt;span class="caps"&gt;SQL&lt;/span&gt; &lt;span class="caps"&gt;API&lt;/span&gt; documentation&lt;/a&gt; makes this possible, and there&amp;#8217;s even a &lt;a href="https://github.com/vizzuality/cartodb-python"&gt;python module&lt;/a&gt; that wraps OAuth2 to simplify things. Although its still in the early stages of development, this module works fine for our current purposes; all we have to do is send it a string that holds the &lt;span class="caps"&gt;SQL&lt;/span&gt; query we want to run. So now we&amp;#8217;ll just write a for-loop that successively builds an &lt;code&gt;INSERT&lt;/code&gt; query for each element in &lt;code&gt;data&lt;/code&gt; (lines 18-20 highlighted&amp;nbsp;below).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;cartodb&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;CartoDBException&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;CartoDBAPIKey&lt;/span&gt;

&lt;span class="n"&gt;user&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="s"&gt;&amp;#39;spencer.g.boucher@gmail.com&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;password&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="s"&gt;&amp;#39;redacted&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;cartodb_domain&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;justmytwospence&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;API_KEY&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;redacted&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;cl&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;CartoDBAPIKey&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;API_KEY&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cartodb_domain&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;reading&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;alt&lt;/span&gt;     &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;reading&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;alt&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;device&lt;/span&gt;  &lt;span class="o"&gt;=&lt;/span&gt;     &lt;span class="n"&gt;reading&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;device&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;lat&lt;/span&gt;     &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;reading&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;lat&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;lon&lt;/span&gt;     &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;reading&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;lon&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;os&lt;/span&gt;      &lt;span class="o"&gt;=&lt;/span&gt;     &lt;span class="n"&gt;reading&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;os&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;t&lt;/span&gt;       &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;reading&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;t&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;version&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;     &lt;span class="n"&gt;reading&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;version&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;query_string&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;INSERT INTO openpaths_justmytwospence (alt, date, device, lat,  lon, os, version, the_geom) &amp;quot;&lt;/span&gt;
                       &lt;span class="s"&gt;&amp;quot;VALUES ({0}, abstime({1}), &amp;#39;{2}&amp;#39;, {3}, {4}, &amp;#39;{5}&amp;#39;, &amp;#39;{6}&amp;#39;, ST_ SetSRID(ST_Point({4}, {3}), 4326))&amp;quot;&lt;/span&gt;
                      &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;alt&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;device&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lat&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lon&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;version&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;cl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sql&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;query_string&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="n"&gt;CartoDBException&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;some error ocurred&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;A few&amp;nbsp;notes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It would certainly be faster to insert all of the new data into the
    database using a single &lt;code&gt;INSERT&lt;/code&gt; statement, but that would require
    some more tedious text parsing and execution speed isn&amp;#8217;t
    particularly important to us. As it stands, it takes about six
    seconds to post a day&amp;#8217;s worth of&amp;nbsp;data.&lt;/li&gt;
&lt;li&gt;One posgreSQL &amp;#8220;gotcha&amp;#8221; had me hung up for quite some time: single
    quotes parse fine but double quotes do&amp;nbsp;not.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ST_SetSRID&lt;/code&gt; is a &lt;a href="http://postgis.org/docs/ST_SetSRID.html"&gt;PostGIS command&lt;/a&gt; that converts a lon/lat pair
    (in that order - another &amp;#8220;gotcha&amp;#8221;) to the necessary geometry&amp;nbsp;object.  &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Last but not least, we need this script to run automatically. Because we&amp;#8217;ve written the script to transplant 24 hours of data, we&amp;#8217;ll need to run it once a day in order to capture all of the data that&amp;#8217;s being generated. I tried to set up my web host, &lt;a href="https://laughingsquid.us/"&gt;LaughingSquid&lt;/a&gt;, to do this, but unfortunately they don&amp;#8217;t grant shell access so we can&amp;#8217;t install all those fancy python modules that we&amp;#8217;ve already used. Its totally possible to rewrite the script to use only modules from the &lt;a href="http://docs.python.org/2/library/"&gt;Python Standard Library&lt;/a&gt;, but this would turn a simple task into a tedious one. Manually implementing OAuth in particular would be a total pain in the rear, and classes are just about to resume after all, so a different solution is in order. Let&amp;#8217;s spin up a &lt;a href="http://aws.amazon.com/"&gt;&amp;#8220;micro&amp;#8221; &lt;span class="caps"&gt;EC2&lt;/span&gt; instance&lt;/a&gt; instead. This gives us free reign to install whatever we need for the low low cost of ¢.02 per hour. This does start to add up, but our Master&amp;#8217;s program gives us some pretty substantial Amazon Web Services credit that goes mostly unused, so we aren&amp;#8217;t too upset :). &lt;span class="caps"&gt;UPDATE&lt;/span&gt;: A new post provides details about how to schedule Amazon &lt;span class="caps"&gt;EC2&lt;/span&gt; instances - &lt;a href="http://www.spencerboucher.com/ec2-apis/"&gt;http://www.spencerboucher.com/ec2-apis/&lt;/a&gt;.  &lt;/p&gt;
&lt;p&gt;After &lt;code&gt;pip install&lt;/code&gt;ing everything we need and &lt;code&gt;scp&lt;/code&gt;ing our python script (let&amp;#8217;s call it update.py) into the home directory of our remote server, all we need to do is set up a crontab with the &lt;code&gt;crontab -e&lt;/code&gt; command and add the following&amp;nbsp;line:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;@daily /usr/bin/python ~/update.py
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;@daily&lt;/code&gt; is actually a shortcut for &lt;code&gt;* * * * *&lt;/code&gt;, where each asterix is a
placeholder for the (respectively) minute, hour, day of month, month,
and day of week that the script should executed. This shortcut defaults
to midnight every day, which is really as good as anything for our&amp;nbsp;purposes.  &lt;/p&gt;
&lt;p&gt;Voilà! Now we can step back and relax, knowing that we don&amp;#8217;t have to do a single thing and our map will continue to show the most up-to-date data&amp;nbsp;available.  &lt;/p&gt;
&lt;p&gt;A few final notes: 
-   We might reasonably want to lag our script by a week or so, for security/privacy reasons.
-   As far as I can tell, the location readings are recorded in a &lt;a href="http://en.wikipedia.org/wiki/Unix_time"&gt;&lt;span class="caps"&gt;POSIX&lt;/span&gt; time&lt;/a&gt; and have not been adjusted by time zone, so they are still in the &lt;a href="http://en.wikipedia.org/wiki/Coordinated_Universal_Time"&gt;&lt;span class="caps"&gt;UTC&lt;/span&gt;&lt;/a&gt; time zone. This means that they are 8 hours off from the actual time in California, where I usually am. This doesn&amp;#8217;t bother me too much at the moment because the visualization is still relatively low resolution in the time domain anyways. At some point I might implement the relevant transformation, but this will raise its own issues because I won&amp;#8217;t &lt;em&gt;always&lt;/em&gt; be in California, not to mention all that Daylight Savings nonsense.
-   [Click here for an addendum to this post that will take you through how to schedule the &lt;span class="caps"&gt;EC2&lt;/span&gt; instance and avoid having it run&amp;nbsp;24/7][]&lt;/p&gt;
&lt;p&gt;[Click here for an addendum to this post that will take you through
  how to schedule the &lt;span class="caps"&gt;EC2&lt;/span&gt; instance and avoid having it run 24/7]: http://www.spencerboucher.com/ec2-apis/
    &amp;#8220;Scheduling tasks in the cloud with &lt;span class="caps"&gt;EC2&lt;/span&gt;&amp;nbsp;APIs&amp;#8221;&lt;/p&gt;</summary><category term="api"></category><category term="aws"></category><category term="cartoDB"></category><category term="cartography"></category><category term="cron"></category><category term="ec2"></category><category term="map"></category><category term="quantifiedSelf"></category></entry><entry><title>Map-time at Stamen</title><link href="http://spencerboucher.com/map-time-at-stamen.html" rel="alternate"></link><updated>2013-12-01T02:37:00-08:00</updated><author><name>Spencer Boucher</name></author><id>tag:spencerboucher.com,2013-12-01:map-time-at-stamen.html</id><summary type="html">&lt;p&gt;Last week, a classmate and I took a break from coursework to attend one of the many great Meetup events that San Francisco has to offer for data science practitioners. I’ve been pushing myself to attend at least one data-centric Meetup every week, because these events are one of the most amazing parts about going to school in the same place where so many of the biggest names work. To be honest, I believe that becoming a presence in the data science scene and meeting the movers and shakers is equally if not more important than&amp;nbsp;coursework.  &lt;/p&gt;
&lt;p&gt;I actually attended 3 meetups last week, one about D3.js at Trulia &lt;span class="caps"&gt;HQ&lt;/span&gt;, one about &lt;span class="caps"&gt;GIS&lt;/span&gt; technologies and the Code for America &lt;span class="caps"&gt;HQ&lt;/span&gt;, and one about mapping at Stamen &lt;span class="caps"&gt;HQ&lt;/span&gt;. I picked all three because they are relevant to a geospatial data visualization that I am working on for my practicum at AutoGrid, but the last one is what I’m going to talk a bit about, because it was the most&amp;nbsp;hands-on.  &lt;/p&gt;
&lt;p&gt;The workshop took place at Stamen Design’s headquarters in the Mission and was led by Eric Theise; you can see his beautiful/informative slides (created using &lt;a href="http://lab.hakim.se/reveal-js/#/"&gt;reveal.js&lt;/a&gt;) &lt;a href="http://erictheise.com/maptime_platform_slides/#/"&gt;here&lt;/a&gt;. Some useful Q&amp;amp;A happened on &lt;a href="http://www.meetup.com/Maptime-SF/events/147110652"&gt;the Meetup event page as well&lt;/a&gt;.  &lt;/p&gt;
&lt;p&gt;This was actually a two-part workshop, but it was relatively painless to follow the instructions and get up to speed for the part &lt;span class="caps"&gt;II&lt;/span&gt;, so you should really give it a shot even now if it looks&amp;nbsp;interesting.  &lt;/p&gt;
&lt;p&gt;First we got postgres up and running on our machines. I have local installations of MySQL, MongoDB, Hadoop and Hive up and running thanks to our course in Distributed Databases, but our class didn’t have time to get to postgres within a single credit hour. This, despite the fact that our professor admits to postgres being the best database to use if you have anything to say about&amp;nbsp;it.  &lt;/p&gt;
&lt;p&gt;Next, we populated our database with some data from OpenStreetMap. Mike Migurski extracts data from &lt;span class="caps"&gt;OSM&lt;/span&gt; for major metropolitan areas on a semi-regular basis, so we used the San Francisco data &lt;a href="http://metro.teczno.com/#san-francisco"&gt;available on his web site&lt;/a&gt; via &lt;a href="http://wiki.openstreetmap.org/wiki/Osm2pgsql"&gt;osm2pgsql&lt;/a&gt;, a command-line utility that loads OpenStreetMap data into PostgreSQL&amp;nbsp;databases.  &lt;/p&gt;
&lt;p&gt;Then we used &lt;a href="https://www.mapbox.com/tilemill/"&gt;TileMill&lt;/a&gt;, MapBox’s desktop application, to visualize our newborn database. We discovered how remarkably easy it can be to create vector layers for data contained in such a postGIS database using the same old &lt;span class="caps"&gt;SQL&lt;/span&gt; and &lt;span class="caps"&gt;CSS&lt;/span&gt; syntax you already know and love. Eric introduced us to some sensible pre-baked &lt;a href="https://github.com/gravitystorm/openstreetmap-carto"&gt;CartoCSS boilerplate&lt;/a&gt; courtesy of Andy&amp;nbsp;Allen.  &lt;/p&gt;
&lt;p&gt;Lastly, we used a nifty feature of TileMill to actually bake our own map tiles and serve them up for use in our own maps. Note that if you want to do this, you’ll need the &lt;a href="https://github.com/mapbox/mbutil"&gt;mbutil command-line utility&lt;/a&gt;, not currently mentioned in the slide&amp;nbsp;deck.  &lt;/p&gt;
&lt;p&gt;Not too shabby for 2 hours on a Wednesday night. Many thanks to the guys at Stamen for hosting, especially Eric for all his work on the slides. Not to mention the many other brilliant people who have made the tools and resources that allow something this involved and grandiose to be done on a laptop by someone who is still learning the ropes. Hands-on workshops like this are one of the best ways to learn these technologies. Case in point, I may not have ever stumbled across Mike or Andy’s resources had I not been learning directly from people who are intimately familiar with the practical ins and outs of digital&amp;nbsp;cartography.  &lt;/p&gt;
&lt;p&gt;Digital mapping is rapidly capturing my interest because of the beautifully functional things one can do with it, and it seems like an amazing time to be learning it, because the ecosystem is beginning to really flourish. Looking forward to more&amp;nbsp;events!  &lt;/p&gt;</summary><category term="cartography"></category><category term="maps"></category></entry></feed>